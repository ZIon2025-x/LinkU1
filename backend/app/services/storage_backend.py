"""
å­˜å‚¨åç«¯æŠ½è±¡å±‚
æ”¯æŒæœ¬åœ°æ–‡ä»¶å­˜å‚¨å’Œäº‘å­˜å‚¨ï¼ˆAWS S3ã€Cloudflare R2ï¼‰
"""

import os
import logging
import threading
from abc import ABC, abstractmethod
from pathlib import Path
from typing import Optional, List, BinaryIO
from datetime import datetime, timedelta

logger = logging.getLogger(__name__)


class StorageBackend(ABC):
    """å­˜å‚¨åç«¯æŠ½è±¡åŸºç±»"""
    
    @abstractmethod
    def upload(self, content: bytes, path: str) -> str:
        """
        ä¸Šä¼ æ–‡ä»¶
        
        Args:
            content: æ–‡ä»¶å†…å®¹
            path: å­˜å‚¨è·¯å¾„ï¼ˆç›¸å¯¹è·¯å¾„ï¼‰
            
        Returns:
            è®¿é—® URL
        """
        pass
    
    @abstractmethod
    def download(self, path: str) -> Optional[bytes]:
        """
        ä¸‹è½½æ–‡ä»¶
        
        Args:
            path: å­˜å‚¨è·¯å¾„ï¼ˆç›¸å¯¹è·¯å¾„ï¼‰
            
        Returns:
            æ–‡ä»¶å†…å®¹ï¼Œå¦‚æœä¸å­˜åœ¨è¿”å› None
        """
        pass
    
    @abstractmethod
    def delete(self, path: str) -> bool:
        """
        åˆ é™¤æ–‡ä»¶
        
        Args:
            path: å­˜å‚¨è·¯å¾„ï¼ˆç›¸å¯¹è·¯å¾„ï¼‰
            
        Returns:
            æ˜¯å¦æˆåŠŸ
        """
        pass
    
    @abstractmethod
    def delete_directory(self, path: str) -> bool:
        """
        åˆ é™¤ç›®å½•åŠå…¶æ‰€æœ‰å†…å®¹
        
        Args:
            path: ç›®å½•è·¯å¾„ï¼ˆç›¸å¯¹è·¯å¾„ï¼‰
            
        Returns:
            æ˜¯å¦æˆåŠŸ
        """
        pass
    
    @abstractmethod
    def exists(self, path: str) -> bool:
        """
        æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨
        
        Args:
            path: å­˜å‚¨è·¯å¾„ï¼ˆç›¸å¯¹è·¯å¾„ï¼‰
            
        Returns:
            æ˜¯å¦å­˜åœ¨
        """
        pass
    
    @abstractmethod
    def list_files(self, directory: str) -> List[str]:
        """
        åˆ—å‡ºç›®å½•ä¸­çš„æ–‡ä»¶
        
        Args:
            directory: ç›®å½•è·¯å¾„ï¼ˆç›¸å¯¹è·¯å¾„ï¼‰
            
        Returns:
            æ–‡ä»¶è·¯å¾„åˆ—è¡¨
        """
        pass
    
    @abstractmethod
    def move(self, src_path: str, dst_path: str) -> bool:
        """
        ç§»åŠ¨æ–‡ä»¶
        
        Args:
            src_path: æºè·¯å¾„ï¼ˆç›¸å¯¹è·¯å¾„ï¼‰
            dst_path: ç›®æ ‡è·¯å¾„ï¼ˆç›¸å¯¹è·¯å¾„ï¼‰
            
        Returns:
            æ˜¯å¦æˆåŠŸ
        """
        pass
    
    @abstractmethod
    def get_url(self, path: str) -> str:
        """
        è·å–æ–‡ä»¶çš„è®¿é—® URL
        
        Args:
            path: å­˜å‚¨è·¯å¾„ï¼ˆç›¸å¯¹è·¯å¾„ï¼‰
            
        Returns:
            è®¿é—® URL
        """
        pass
    
    @abstractmethod
    def get_file_size(self, path: str) -> Optional[int]:
        """
        è·å–æ–‡ä»¶å¤§å°
        
        Args:
            path: å­˜å‚¨è·¯å¾„ï¼ˆç›¸å¯¹è·¯å¾„ï¼‰
            
        Returns:
            æ–‡ä»¶å¤§å°ï¼ˆå­—èŠ‚ï¼‰ï¼Œå¦‚æœä¸å­˜åœ¨è¿”å› None
        """
        pass


class LocalStorageBackend(StorageBackend):
    """æœ¬åœ°æ–‡ä»¶å­˜å‚¨åç«¯"""
    
    def __init__(self, base_dir: Optional[str] = None, base_url: Optional[str] = None):
        """
        åˆå§‹åŒ–æœ¬åœ°å­˜å‚¨åç«¯
        
        Args:
            base_dir: åŸºç¡€å­˜å‚¨ç›®å½•ï¼Œé»˜è®¤æ ¹æ®ç¯å¢ƒè‡ªåŠ¨é€‰æ‹©
            base_url: åŸºç¡€ URLï¼Œç”¨äºç”Ÿæˆè®¿é—®é“¾æ¥
        """
        # æ£€æµ‹éƒ¨ç½²ç¯å¢ƒ
        railway_env = os.getenv("RAILWAY_ENVIRONMENT")
        
        if base_dir:
            self.base_dir = Path(base_dir)
        elif railway_env:
            self.base_dir = Path("/data/uploads")
        else:
            self.base_dir = Path("uploads")
        
        # ç¡®ä¿åŸºç¡€ç›®å½•å­˜åœ¨
        self.base_dir.mkdir(parents=True, exist_ok=True)
        
        # åŸºç¡€ URLï¼ˆä½¿ç”¨å‰ç«¯ URLï¼Œå› ä¸º Vercel ä»£ç† /uploads/ è¯·æ±‚åˆ°åç«¯ï¼‰
        if base_url:
            self.base_url = base_url.rstrip('/')
        else:
            from app.config import Config
            self.base_url = Config.FRONTEND_URL.rstrip('/')
        
        logger.info(f"æœ¬åœ°å­˜å‚¨åç«¯åˆå§‹åŒ–: base_dir={self.base_dir}, base_url={self.base_url}")
    
    def _get_full_path(self, path: str) -> Path:
        """è·å–å®Œæ•´è·¯å¾„ï¼ˆå¸¦å®‰å…¨æ£€æŸ¥ï¼‰"""
        # ç§»é™¤å¼€å¤´çš„æ–œæ 
        path = path.lstrip('/')
        
        # å®‰å…¨æ£€æŸ¥ï¼šé˜²æ­¢è·¯å¾„éå†æ”»å‡»
        if '..' in path or path.startswith('/'):
            raise ValueError(f"ä¸å®‰å…¨çš„è·¯å¾„: {path}")
        
        full_path = self.base_dir / path
        
        # ç¡®ä¿è·¯å¾„åœ¨ base_dir å†…ï¼ˆé˜²æ­¢è·¯å¾„éå†ï¼‰
        try:
            full_path.resolve().relative_to(self.base_dir.resolve())
        except ValueError:
            raise ValueError(f"è·¯å¾„è¶…å‡ºå…è®¸èŒƒå›´: {path}")
        
        return full_path
    
    def _ensure_directory(self, path: Path) -> None:
        """ç¡®ä¿ç›®å½•å­˜åœ¨"""
        path.parent.mkdir(parents=True, exist_ok=True)
    
    def upload(self, content: bytes, path: str) -> str:
        """ä¸Šä¼ æ–‡ä»¶åˆ°æœ¬åœ°"""
        try:
            full_path = self._get_full_path(path)
            self._ensure_directory(full_path)
            
            with open(full_path, 'wb') as f:
                f.write(content)
            
            logger.debug(f"æ–‡ä»¶ä¸Šä¼ æˆåŠŸ: {path}")
            return self.get_url(path)
            
        except Exception as e:
            logger.error(f"æ–‡ä»¶ä¸Šä¼ å¤±è´¥: {path}, é”™è¯¯: {e}")
            raise
    
    def download(self, path: str) -> Optional[bytes]:
        """ä»æœ¬åœ°ä¸‹è½½æ–‡ä»¶"""
        try:
            full_path = self._get_full_path(path)
            
            if not full_path.exists() or not full_path.is_file():
                return None
            
            with open(full_path, 'rb') as f:
                return f.read()
                
        except Exception as e:
            logger.error(f"æ–‡ä»¶ä¸‹è½½å¤±è´¥: {path}, é”™è¯¯: {e}")
            return None
    
    def delete(self, path: str) -> bool:
        """åˆ é™¤æœ¬åœ°æ–‡ä»¶"""
        try:
            full_path = self._get_full_path(path)
            
            if full_path.exists() and full_path.is_file():
                full_path.unlink()
                logger.debug(f"æ–‡ä»¶åˆ é™¤æˆåŠŸ: {path}")
                return True
            
            return False
            
        except Exception as e:
            logger.error(f"æ–‡ä»¶åˆ é™¤å¤±è´¥: {path}, é”™è¯¯: {e}")
            return False
    
    def delete_directory(self, path: str) -> bool:
        """åˆ é™¤æœ¬åœ°ç›®å½•åŠå…¶æ‰€æœ‰å†…å®¹"""
        try:
            import shutil
            full_path = self._get_full_path(path)
            
            if full_path.exists() and full_path.is_dir():
                shutil.rmtree(full_path)
                logger.debug(f"ç›®å½•åˆ é™¤æˆåŠŸ: {path}")
                return True
            
            return False
            
        except Exception as e:
            logger.error(f"ç›®å½•åˆ é™¤å¤±è´¥: {path}, é”™è¯¯: {e}")
            return False
    
    def exists(self, path: str) -> bool:
        """æ£€æŸ¥æœ¬åœ°æ–‡ä»¶æ˜¯å¦å­˜åœ¨"""
        full_path = self._get_full_path(path)
        return full_path.exists() and full_path.is_file()
    
    def list_files(self, directory: str) -> List[str]:
        """åˆ—å‡ºæœ¬åœ°ç›®å½•ä¸­çš„æ–‡ä»¶"""
        try:
            full_path = self._get_full_path(directory)
            
            if not full_path.exists() or not full_path.is_dir():
                return []
            
            files = []
            for item in full_path.iterdir():
                if item.is_file():
                    # è¿”å›ç›¸å¯¹äº base_dir çš„è·¯å¾„
                    rel_path = str(item.relative_to(self.base_dir))
                    files.append(rel_path)
            
            return files
            
        except Exception as e:
            logger.error(f"åˆ—å‡ºç›®å½•å¤±è´¥: {directory}, é”™è¯¯: {e}")
            return []
    
    def list_files_with_metadata(self, directory: str) -> List[dict]:
        """
        åˆ—å‡ºæœ¬åœ°ç›®å½•ä¸­çš„æ–‡ä»¶åŠå…¶å…ƒæ•°æ®
        
        Returns:
            List of dicts with keys: 'key', 'last_modified', 'size'
        """
        try:
            from datetime import datetime
            from app.utils.time_utils import file_timestamp_to_utc
            
            full_path = self._get_full_path(directory)
            
            if not full_path.exists() or not full_path.is_dir():
                return []
            
            files = []
            for item in full_path.iterdir():
                if item.is_file():
                    # è¿”å›ç›¸å¯¹äº base_dir çš„è·¯å¾„
                    rel_path = str(item.relative_to(self.base_dir))
                    stat = item.stat()
                    # å°†æ–‡ä»¶ç³»ç»Ÿæ—¶é—´æˆ³è½¬æ¢ä¸º UTC datetime
                    last_modified = file_timestamp_to_utc(stat.st_mtime)
                    files.append({
                        'key': rel_path,
                        'last_modified': last_modified,
                        'size': stat.st_size
                    })
            
            return files
            
        except Exception as e:
            logger.error(f"åˆ—å‡ºç›®å½•ï¼ˆå«å…ƒæ•°æ®ï¼‰å¤±è´¥: {directory}, é”™è¯¯: {e}")
            return []
    
    def move(self, src_path: str, dst_path: str) -> bool:
        """ç§»åŠ¨æœ¬åœ°æ–‡ä»¶"""
        try:
            src_full = self._get_full_path(src_path)
            dst_full = self._get_full_path(dst_path)
            
            if not src_full.exists():
                logger.warning(f"æºæ–‡ä»¶ä¸å­˜åœ¨: {src_path}")
                return False
            
            self._ensure_directory(dst_full)
            
            import shutil
            shutil.move(str(src_full), str(dst_full))
            logger.debug(f"æ–‡ä»¶ç§»åŠ¨æˆåŠŸ: {src_path} -> {dst_path}")
            return True
            
        except Exception as e:
            logger.error(f"æ–‡ä»¶ç§»åŠ¨å¤±è´¥: {src_path} -> {dst_path}, é”™è¯¯: {e}")
            return False
    
    def get_url(self, path: str) -> str:
        """è·å–æœ¬åœ°æ–‡ä»¶çš„è®¿é—® URL"""
        # ç§»é™¤å¼€å¤´çš„æ–œæ 
        path = path.lstrip('/')
        return f"{self.base_url}/uploads/{path}"
    
    def get_file_size(self, path: str) -> Optional[int]:
        """è·å–æœ¬åœ°æ–‡ä»¶å¤§å°"""
        try:
            full_path = self._get_full_path(path)
            
            if full_path.exists() and full_path.is_file():
                return full_path.stat().st_size
            
            return None
            
        except Exception as e:
            logger.error(f"è·å–æ–‡ä»¶å¤§å°å¤±è´¥: {path}, é”™è¯¯: {e}")
            return None


class S3StorageBackend(StorageBackend):
    """AWS S3 / Cloudflare R2 å­˜å‚¨åç«¯"""
    
    def __init__(
        self,
        bucket_name: str,
        access_key_id: Optional[str] = None,
        secret_access_key: Optional[str] = None,
        endpoint_url: Optional[str] = None,
        region_name: str = "auto",
        public_url: Optional[str] = None
    ):
        """
        åˆå§‹åŒ– S3 å­˜å‚¨åç«¯
        
        Args:
            bucket_name: S3 å­˜å‚¨æ¡¶åç§°
            access_key_id: AWS Access Key ID
            secret_access_key: AWS Secret Access Key
            endpoint_url: è‡ªå®šä¹‰ç«¯ç‚¹ URLï¼ˆç”¨äº R2 ç­‰å…¼å®¹æœåŠ¡ï¼‰
            region_name: AWS åŒºåŸŸ
            public_url: å…¬å¼€è®¿é—®çš„ URL å‰ç¼€
        """
        self.bucket_name = bucket_name
        self.public_url = public_url.rstrip('/') if public_url else None
        
        # ä»ç¯å¢ƒå˜é‡è·å–å‡­è¯
        self.access_key_id = access_key_id or os.getenv('AWS_ACCESS_KEY_ID') or os.getenv('R2_ACCESS_KEY_ID')
        self.secret_access_key = secret_access_key or os.getenv('AWS_SECRET_ACCESS_KEY') or os.getenv('R2_SECRET_ACCESS_KEY')
        raw_endpoint_url = endpoint_url or os.getenv('S3_ENDPOINT_URL') or os.getenv('R2_ENDPOINT_URL')
        
        # å¤„ç†endpoint URLï¼šå¦‚æœåŒ…å«bucketåç§°ï¼Œå»æ‰å®ƒï¼ˆboto3ä¼šåœ¨APIè°ƒç”¨ä¸­ä½¿ç”¨bucket_nameå‚æ•°ï¼‰
        if raw_endpoint_url:
            # R2 endpointæ ¼å¼åº”è¯¥æ˜¯: https://{account_id}.r2.cloudflarestorage.com
            # å¦‚æœURLæœ«å°¾åŒ…å«bucketåç§°ï¼Œå»æ‰å®ƒ
            if raw_endpoint_url.endswith(f'/{bucket_name}'):
                self.endpoint_url = raw_endpoint_url[:-len(f'/{bucket_name}')]
                logger.info(f"ä»endpoint URLä¸­ç§»é™¤äº†bucketåç§°: {raw_endpoint_url} -> {self.endpoint_url}")
            else:
                self.endpoint_url = raw_endpoint_url
        else:
            self.endpoint_url = None
        
        self.region_name = region_name
        
        # å»¶è¿Ÿåˆå§‹åŒ– S3 å®¢æˆ·ç«¯
        self._client = None
        
        logger.info(f"S3 å­˜å‚¨åç«¯åˆå§‹åŒ–: bucket={bucket_name}, endpoint={self.endpoint_url}")
    
    @property
    def client(self):
        """å»¶è¿Ÿåˆå§‹åŒ– S3 å®¢æˆ·ç«¯"""
        if self._client is None:
            try:
                import boto3
                self._client = boto3.client(
                    's3',
                    aws_access_key_id=self.access_key_id,
                    aws_secret_access_key=self.secret_access_key,
                    endpoint_url=self.endpoint_url,
                    region_name=self.region_name
                )
            except ImportError:
                raise ImportError("è¯·å®‰è£… boto3: pip install boto3")
        return self._client
    
    # ğŸ”’ å®‰å…¨ä¿®å¤ï¼šå…è®¸ä¸Šä¼ çš„ MIME ç±»å‹ç™½åå•
    ALLOWED_CONTENT_TYPES = {
        'image/jpeg', 'image/png', 'image/webp', 'image/gif',
        'image/heic', 'image/heif', 'image/avif',  # iOS å¸¸è§æ ¼å¼
        'application/pdf',
        'audio/mpeg', 'audio/wav', 'audio/ogg',
        'video/mp4', 'video/webm',
        # æ³¨æ„ï¼šä¸åŒ…å« application/octet-streamï¼Œå› ä¸ºå®ƒæ˜¯å…œåº•ç±»å‹ï¼Œ
        # ä¼šå¯¼è‡´ä»»ä½•æœªè¯†åˆ«æ‰©å±•åçš„æ–‡ä»¶éƒ½èƒ½é€šè¿‡ç™½åå•æ£€æŸ¥
    }
    
    # æ–‡ä»¶å¤§å°ä¸Šé™
    MAX_FILE_SIZE = 50 * 1024 * 1024  # 50MB
    
    def upload(self, content: bytes, path: str) -> str:
        """ä¸Šä¼ æ–‡ä»¶åˆ° S3"""
        try:
            # ç§»é™¤å¼€å¤´çš„æ–œæ 
            path = path.lstrip('/')
            
            # ğŸ”’ å®‰å…¨ä¿®å¤ï¼šæ–‡ä»¶å¤§å°æ£€æŸ¥
            if len(content) > self.MAX_FILE_SIZE:
                raise ValueError(f"æ–‡ä»¶è¿‡å¤§: {len(content)} å­—èŠ‚ï¼Œä¸Šé™ {self.MAX_FILE_SIZE} å­—èŠ‚")
            
            # æ ¹æ®æ–‡ä»¶æ‰©å±•åè®¾ç½® Content-Type
            content_type = self._get_content_type(path)
            
            # ğŸ”’ å®‰å…¨ä¿®å¤ï¼šContent-Type ç™½åå•éªŒè¯
            if content_type not in self.ALLOWED_CONTENT_TYPES:
                logger.warning(f"ä¸å…è®¸çš„ Content-Type: {content_type}ï¼Œæ–‡ä»¶: {path}")
                raise ValueError(f"ä¸å…è®¸çš„æ–‡ä»¶ç±»å‹: {content_type}")
            
            # ğŸ”’ å®‰å…¨ä¿®å¤ï¼šè®¾ç½® ACL ä¸º privateï¼Œé˜²æ­¢ bucket é”™è¯¯é…ç½®å¯¼è‡´æ–‡ä»¶å…¬å¼€
            self.client.put_object(
                Bucket=self.bucket_name,
                Key=path,
                Body=content,
                ContentType=content_type,
                ACL='private'
            )
            
            logger.debug(f"S3 æ–‡ä»¶ä¸Šä¼ æˆåŠŸ: {path}")
            return self.get_url(path)
            
        except Exception as e:
            logger.error(f"S3 æ–‡ä»¶ä¸Šä¼ å¤±è´¥: {path}, é”™è¯¯: {e}")
            raise
    
    def download(self, path: str) -> Optional[bytes]:
        """ä» S3 ä¸‹è½½æ–‡ä»¶"""
        try:
            path = path.lstrip('/')
            
            response = self.client.get_object(
                Bucket=self.bucket_name,
                Key=path
            )
            return response['Body'].read()
            
        except self.client.exceptions.NoSuchKey:
            return None
        except Exception as e:
            logger.error(f"S3 æ–‡ä»¶ä¸‹è½½å¤±è´¥: {path}, é”™è¯¯: {e}")
            return None
    
    def delete(self, path: str) -> bool:
        """åˆ é™¤ S3 æ–‡ä»¶"""
        try:
            path = path.lstrip('/')
            
            self.client.delete_object(
                Bucket=self.bucket_name,
                Key=path
            )
            
            logger.debug(f"S3 æ–‡ä»¶åˆ é™¤æˆåŠŸ: {path}")
            return True
            
        except Exception as e:
            logger.error(f"S3 æ–‡ä»¶åˆ é™¤å¤±è´¥: {path}, é”™è¯¯: {e}")
            return False
    
    def delete_directory(self, path: str) -> bool:
        """åˆ é™¤ S3 ç›®å½•ï¼ˆå‰ç¼€ï¼‰ä¸‹çš„æ‰€æœ‰æ–‡ä»¶"""
        try:
            path = path.lstrip('/').rstrip('/') + '/'
            
            # åˆ—å‡ºæ‰€æœ‰åŒ¹é…çš„å¯¹è±¡
            paginator = self.client.get_paginator('list_objects_v2')
            
            objects_to_delete = []
            for page in paginator.paginate(Bucket=self.bucket_name, Prefix=path):
                if 'Contents' in page:
                    for obj in page['Contents']:
                        objects_to_delete.append({'Key': obj['Key']})
            
            if objects_to_delete:
                # æ‰¹é‡åˆ é™¤
                self.client.delete_objects(
                    Bucket=self.bucket_name,
                    Delete={'Objects': objects_to_delete}
                )
                logger.debug(f"S3 ç›®å½•åˆ é™¤æˆåŠŸ: {path}, å…± {len(objects_to_delete)} ä¸ªæ–‡ä»¶")
            
            return True
            
        except Exception as e:
            logger.error(f"S3 ç›®å½•åˆ é™¤å¤±è´¥: {path}, é”™è¯¯: {e}")
            return False
    
    def exists(self, path: str) -> bool:
        """æ£€æŸ¥ S3 æ–‡ä»¶æ˜¯å¦å­˜åœ¨"""
        try:
            path = path.lstrip('/')
            
            self.client.head_object(
                Bucket=self.bucket_name,
                Key=path
            )
            return True
            
        except:
            return False
    
    def list_files(self, directory: str) -> List[str]:
        """åˆ—å‡º S3 ç›®å½•ä¸­çš„æ–‡ä»¶"""
        try:
            directory = directory.lstrip('/').rstrip('/') + '/'
            
            files = []
            paginator = self.client.get_paginator('list_objects_v2')
            
            for page in paginator.paginate(Bucket=self.bucket_name, Prefix=directory):
                if 'Contents' in page:
                    for obj in page['Contents']:
                        files.append(obj['Key'])
            
            return files
            
        except Exception as e:
            logger.error(f"S3 åˆ—å‡ºç›®å½•å¤±è´¥: {directory}, é”™è¯¯: {e}")
            return []
    
    def list_files_with_metadata(self, directory: str) -> List[dict]:
        """
        åˆ—å‡º S3 ç›®å½•ä¸­çš„æ–‡ä»¶åŠå…¶å…ƒæ•°æ®
        
        Returns:
            List of dicts with keys: 'key', 'last_modified', 'size'
        """
        try:
            directory = directory.lstrip('/').rstrip('/') + '/'
            
            files = []
            paginator = self.client.get_paginator('list_objects_v2')
            
            for page in paginator.paginate(Bucket=self.bucket_name, Prefix=directory):
                if 'Contents' in page:
                    for obj in page['Contents']:
                        files.append({
                            'key': obj['Key'],
                            'last_modified': obj['LastModified'],
                            'size': obj.get('Size', 0)
                        })
            
            return files
            
        except Exception as e:
            logger.error(f"S3 åˆ—å‡ºç›®å½•ï¼ˆå«å…ƒæ•°æ®ï¼‰å¤±è´¥: {directory}, é”™è¯¯: {e}")
            return []
    
    def move(self, src_path: str, dst_path: str) -> bool:
        """ç§»åŠ¨ S3 æ–‡ä»¶ï¼ˆå¤åˆ¶ååˆ é™¤ï¼‰"""
        try:
            src_path = src_path.lstrip('/')
            dst_path = dst_path.lstrip('/')
            
            # å…ˆæ£€æŸ¥æºæ–‡ä»¶æ˜¯å¦å­˜åœ¨
            try:
                self.client.head_object(Bucket=self.bucket_name, Key=src_path)
                logger.debug(f"S3 æºæ–‡ä»¶å­˜åœ¨: {src_path}")
            except self.client.exceptions.ClientError as e:
                error_code = e.response.get('Error', {}).get('Code', '')
                if error_code == '404' or error_code == 'NoSuchKey':
                    logger.error(f"S3 æºæ–‡ä»¶ä¸å­˜åœ¨: {src_path}, bucket={self.bucket_name}")
                    # å°è¯•åˆ—å‡ºç›®å½•ä¸­çš„æ–‡ä»¶ï¼Œå¸®åŠ©è°ƒè¯•
                    try:
                        directory = '/'.join(src_path.split('/')[:-1]) + '/'
                        files = self.list_files(directory)
                        logger.error(f"ç›®å½• {directory} ä¸­çš„æ–‡ä»¶: {files[:10]}")  # åªæ˜¾ç¤ºå‰10ä¸ª
                    except Exception as list_error:
                        logger.error(f"åˆ—å‡ºç›®å½•å¤±è´¥: {list_error}")
                    return False
                else:
                    logger.warning(f"S3 æ£€æŸ¥æºæ–‡ä»¶æ—¶å‡ºé”™: {src_path}, é”™è¯¯: {e}")
                    # ç»§ç»­å°è¯•ç§»åŠ¨ï¼Œå¯èƒ½æ˜¯æƒé™é—®é¢˜
            
            # å¤åˆ¶æ–‡ä»¶
            self.client.copy_object(
                Bucket=self.bucket_name,
                CopySource={'Bucket': self.bucket_name, 'Key': src_path},
                Key=dst_path
            )
            
            # åˆ é™¤åŸæ–‡ä»¶
            self.client.delete_object(
                Bucket=self.bucket_name,
                Key=src_path
            )
            
            logger.info(f"S3 æ–‡ä»¶ç§»åŠ¨æˆåŠŸ: {src_path} -> {dst_path}")
            return True
            
        except Exception as e:
            logger.error(f"S3 æ–‡ä»¶ç§»åŠ¨å¤±è´¥: {src_path} -> {dst_path}, bucket={self.bucket_name}, é”™è¯¯: {e}")
            import traceback
            logger.error(f"è¯¦ç»†é”™è¯¯: {traceback.format_exc()}")
            return False
    
    def get_url(self, path: str) -> str:
        """è·å– S3 æ–‡ä»¶çš„è®¿é—® URL"""
        path = path.lstrip('/')
        
        if self.public_url:
            # ä½¿ç”¨å…¬å¼€ URLï¼ˆæ°¸ä¹…æœ‰æ•ˆï¼‰
            base = self.public_url.rstrip('/')
            # ç¡®ä¿è¿”å›ç»å¯¹ URLï¼Œå¦åˆ™å‰ç«¯ img src ä¼šæŒ‰ç›¸å¯¹è·¯å¾„è§£æå¯¼è‡´ä»»åŠ¡å¤§å…ç­‰å¤„å›¾ç‰‡ä¸æ˜¾ç¤º
            if not (base.startswith('http://') or base.startswith('https://')):
                base = f"https://{base}"
            return f"{base}/{path}"
        else:
            # âš ï¸ è­¦å‘Šï¼šæ²¡æœ‰é…ç½® public_urlï¼Œä½¿ç”¨é¢„ç­¾å URLï¼ˆ15åˆ†é’Ÿæœ‰æ•ˆæœŸï¼‰
            # è¿™ä¼šå¯¼è‡´å›¾ç‰‡ URL åœ¨ 15 åˆ†é’Ÿåå¤±æ•ˆï¼
            # å»ºè®®é…ç½® S3_PUBLIC_URL æˆ– R2_PUBLIC_URL ç¯å¢ƒå˜é‡
            logger.warning(
                f"S3 å­˜å‚¨æœªé…ç½® public_urlï¼Œç”Ÿæˆçš„é¢„ç­¾å URL å°†åœ¨ 15 åˆ†é’Ÿåè¿‡æœŸã€‚"
                f"å»ºè®®é…ç½® S3_PUBLIC_URL æˆ– R2_PUBLIC_URL ç¯å¢ƒå˜é‡ä»¥ç”Ÿæˆæ°¸ä¹… URLã€‚"
            )
            # ç”Ÿæˆé¢„ç­¾å URLï¼ˆ15åˆ†é’Ÿæœ‰æ•ˆæœŸï¼Œé™ä½æ³„éœ²é£é™©ï¼‰
            return self.client.generate_presigned_url(
                'get_object',
                Params={'Bucket': self.bucket_name, 'Key': path},
                ExpiresIn=900  # 15åˆ†é’Ÿæœ‰æ•ˆæœŸï¼ˆä»1å°æ—¶é™ä½ï¼Œå¹³è¡¡å®‰å…¨ä¸å¯ç”¨æ€§ï¼‰
            )
    
    def get_file_size(self, path: str) -> Optional[int]:
        """è·å– S3 æ–‡ä»¶å¤§å°"""
        try:
            path = path.lstrip('/')
            
            response = self.client.head_object(
                Bucket=self.bucket_name,
                Key=path
            )
            return response['ContentLength']
            
        except:
            return None
    
    EXTENSION_CONTENT_TYPES = {
        '.jpg': 'image/jpeg', '.jpeg': 'image/jpeg',
        '.png': 'image/png', '.gif': 'image/gif',
        '.webp': 'image/webp',
        '.heic': 'image/heic', '.heif': 'image/heif',
        '.avif': 'image/avif',
        '.pdf': 'application/pdf',
        '.mp3': 'audio/mpeg', '.wav': 'audio/wav', '.ogg': 'audio/ogg',
        '.mp4': 'video/mp4', '.webm': 'video/webm',
    }

    def _get_content_type(self, path: str) -> str:
        """æ ¹æ®æ–‡ä»¶æ‰©å±•åè·å– Content-Typeï¼Œä¼˜å…ˆä½¿ç”¨æ˜¾å¼æ˜ å°„ä»¥é¿å… mimetypes åœ¨æŸäº›ç¯å¢ƒä¸‹ç¼ºå¤±æ¡ç›®"""
        import os
        ext = os.path.splitext(path)[1].lower()
        if ext in self.EXTENSION_CONTENT_TYPES:
            return self.EXTENSION_CONTENT_TYPES[ext]
        import mimetypes
        content_type, _ = mimetypes.guess_type(path)
        return content_type or 'application/octet-stream'


def get_storage_backend() -> StorageBackend:
    """
    è·å–å­˜å‚¨åç«¯å®ä¾‹
    
    æ ¹æ®ç¯å¢ƒå˜é‡é€‰æ‹©ä½¿ç”¨æœ¬åœ°å­˜å‚¨æˆ–äº‘å­˜å‚¨
    
    ç¯å¢ƒå˜é‡:
        STORAGE_BACKEND: "local" | "s3" | "r2"
        S3_BUCKET_NAME: S3 å­˜å‚¨æ¡¶åç§°
        S3_PUBLIC_URL: å…¬å¼€è®¿é—®çš„ URL å‰ç¼€
        
    Returns:
        å­˜å‚¨åç«¯å®ä¾‹
    """
    backend_type = os.getenv('STORAGE_BACKEND', 'local').lower()
    
    if backend_type == 's3':
        return S3StorageBackend(
            bucket_name=os.getenv('S3_BUCKET_NAME', 'linku-uploads'),
            public_url=os.getenv('S3_PUBLIC_URL')
        )
    elif backend_type == 'r2':
        # Cloudflare R2 ä½¿ç”¨ S3 å…¼å®¹ API
        return S3StorageBackend(
            bucket_name=os.getenv('R2_BUCKET_NAME', 'linku-uploads'),
            endpoint_url=os.getenv('R2_ENDPOINT_URL'),
            public_url=os.getenv('R2_PUBLIC_URL')
        )
    else:
        # é»˜è®¤ä½¿ç”¨æœ¬åœ°å­˜å‚¨
        return LocalStorageBackend()


# å…¨å±€å­˜å‚¨åç«¯å®ä¾‹ï¼ˆå»¶è¿Ÿåˆå§‹åŒ–ï¼Œçº¿ç¨‹å®‰å…¨ï¼‰
_storage_backend: Optional[StorageBackend] = None
_storage_lock = threading.Lock()


def get_default_storage() -> StorageBackend:
    """è·å–é»˜è®¤å­˜å‚¨åç«¯å®ä¾‹ï¼ˆçº¿ç¨‹å®‰å…¨ï¼‰"""
    global _storage_backend
    if _storage_backend is None:
        with _storage_lock:
            # åŒé‡æ£€æŸ¥é”å®šæ¨¡å¼
            if _storage_backend is None:
                _storage_backend = get_storage_backend()
    return _storage_backend
