"""
Celery å®šæ—¶ä»»åŠ¡åŒ…è£…
å°†æ‰€æœ‰å®šæ—¶ä»»åŠ¡åŒ…è£…ä¸º Celery ä»»åŠ¡ï¼Œæ”¯æŒ Celery Beat è°ƒåº¦
"""
import logging
import time
from typing import Dict, Any

logger = logging.getLogger(__name__)


def get_redis_distributed_lock(lock_key: str, lock_ttl: int = 3600) -> bool:
    """
    è·å– Redis åˆ†å¸ƒå¼é”ï¼ˆä½¿ç”¨ SETNXï¼‰
    è¿”å› True è¡¨ç¤ºè·å–æˆåŠŸï¼ŒFalse è¡¨ç¤ºé”å·²è¢«å ç”¨
    
    Args:
        lock_key: é”çš„é”®å
        lock_ttl: é”çš„è¿‡æœŸæ—¶é—´ï¼ˆç§’ï¼‰ï¼Œé»˜è®¤1å°æ—¶
    
    Returns:
        bool: æ˜¯å¦æˆåŠŸè·å–é”
    """
    try:
        from app.redis_cache import get_redis_client
        redis_client = get_redis_client()
        
        if not redis_client:
            # Redis ä¸å¯ç”¨æ—¶ï¼Œè¿”å› Trueï¼ˆå…è®¸æ‰§è¡Œï¼Œä½†ä¼šæœ‰å¤šå®ä¾‹é‡å¤æ‰§è¡Œçš„é£é™©ï¼‰
            logger.warning(f"Redis ä¸å¯ç”¨ï¼Œè·³è¿‡åˆ†å¸ƒå¼é”æ£€æŸ¥: {lock_key}")
            return True
        
        # ä½¿ç”¨ SETNX åŸå­æ“ä½œè·å–é”
        lock_value = str(time.time())
        result = redis_client.set(lock_key, lock_value, nx=True, ex=lock_ttl)
        
        if result:
            logger.debug(f"æˆåŠŸè·å–åˆ†å¸ƒå¼é”: {lock_key}")
            return True
        else:
            logger.debug(f"åˆ†å¸ƒå¼é”å·²è¢«å ç”¨: {lock_key}")
            return False
            
    except Exception as e:
        logger.warning(f"è·å–åˆ†å¸ƒå¼é”å¤±è´¥ {lock_key}: {e}ï¼Œå…è®¸æ‰§è¡Œï¼ˆé™çº§å¤„ç†ï¼‰")
        return True  # å‡ºé”™æ—¶å…è®¸æ‰§è¡Œï¼Œé¿å…å› é”æœºåˆ¶æ•…éšœå¯¼è‡´ä»»åŠ¡æ— æ³•æ‰§è¡Œ


def release_redis_distributed_lock(lock_key: str):
    """
    é‡Šæ”¾ Redis åˆ†å¸ƒå¼é”
    
    Args:
        lock_key: é”çš„é”®å
    """
    try:
        from app.redis_cache import get_redis_client
        redis_client = get_redis_client()
        
        if redis_client:
            redis_client.delete(lock_key)
            logger.debug(f"é‡Šæ”¾åˆ†å¸ƒå¼é”: {lock_key}")
    except Exception as e:
        logger.warning(f"é‡Šæ”¾åˆ†å¸ƒå¼é”å¤±è´¥ {lock_key}: {e}")

# è¾…åŠ©å‡½æ•°ï¼šè®°å½• Prometheus æŒ‡æ ‡
def _record_task_metrics(task_name: str, status: str, duration: float):
    """è®°å½•ä»»åŠ¡æ‰§è¡ŒæŒ‡æ ‡"""
    try:
        from app.metrics import record_scheduled_task
        record_scheduled_task(task_name, status, duration)
    except Exception:
        pass  # æŒ‡æ ‡è®°å½•å¤±è´¥ä¸å½±å“ä»»åŠ¡æ‰§è¡Œ

# å°è¯•å¯¼å…¥ Celery
try:
    from app.celery_app import celery_app
    CELERY_AVAILABLE = True
except ImportError:
    logger.warning("Celeryæœªå®‰è£…ï¼Œå°†ä½¿ç”¨åå°çº¿ç¨‹æ–¹å¼æ‰§è¡Œå®šæ—¶ä»»åŠ¡")
    CELERY_AVAILABLE = False
    celery_app = None

if CELERY_AVAILABLE:
    from app.database import SessionLocal
    from app.scheduled_tasks import (
        check_expired_coupons,
        check_expired_invitation_codes,
        check_expired_points,
        check_and_end_activities_sync,
        auto_complete_expired_time_slot_tasks,
        process_expired_verifications,
        check_expired_payment_tasks
    )
    from app.crud import check_and_update_expired_subscriptions
    from app.crud import (
        cancel_expired_tasks,
        update_all_featured_task_experts_response_time,
        revert_unpaid_application_approvals
    )
    from app.main import update_all_users_statistics
    
    @celery_app.task(
        name='app.celery_tasks.cancel_expired_tasks_task',
        bind=True,
        max_retries=3,
        default_retry_delay=60
    )
    def cancel_expired_tasks_task(self):
        """å–æ¶ˆè¿‡æœŸä»»åŠ¡ - Celeryä»»åŠ¡åŒ…è£…"""
        start_time = time.time()
        task_name = 'cancel_expired_tasks_task'
        db = SessionLocal()
        try:
            cancel_expired_tasks(db)
            duration = time.time() - start_time
            logger.info(f"å–æ¶ˆè¿‡æœŸä»»åŠ¡å®Œæˆ (è€—æ—¶: {duration:.2f}ç§’)")
            _record_task_metrics(task_name, "success", duration)
            return {"status": "success", "message": "Expired tasks cancelled"}
        except Exception as e:
            duration = time.time() - start_time
            logger.error(f"å–æ¶ˆè¿‡æœŸä»»åŠ¡å¤±è´¥: {e}", exc_info=True)
            _record_task_metrics(task_name, "error", duration)
            try:
                db.rollback()
            except Exception:
                pass
            # é‡è¯•æœºåˆ¶ï¼šå¯¹äºä¸´æ—¶é”™è¯¯ï¼ˆå¦‚æ•°æ®åº“è¿æ¥é—®é¢˜ï¼‰è¿›è¡Œé‡è¯•
            if self.request.retries < self.max_retries:
                logger.info(f"ä»»åŠ¡å°†é‡è¯• ({self.request.retries + 1}/{self.max_retries})")
                raise self.retry(exc=e)
            raise
        finally:
            db.close()
    
    @celery_app.task(
        name='app.celery_tasks.check_expired_coupons_task',
        bind=True,
        max_retries=3,
        default_retry_delay=60
    )
    def check_expired_coupons_task(self):
        """æ£€æŸ¥è¿‡æœŸä¼˜æƒ åˆ¸ - Celeryä»»åŠ¡åŒ…è£…"""
        start_time = time.time()
        task_name = 'check_expired_coupons_task'
        db = SessionLocal()
        try:
            check_expired_coupons(db)
            duration = time.time() - start_time
            logger.info(f"æ£€æŸ¥è¿‡æœŸä¼˜æƒ åˆ¸å®Œæˆ (è€—æ—¶: {duration:.2f}ç§’)")
            _record_task_metrics(task_name, "success", duration)
            return {"status": "success", "message": "Expired coupons checked"}
        except Exception as e:
            duration = time.time() - start_time
            logger.error(f"æ£€æŸ¥è¿‡æœŸä¼˜æƒ åˆ¸å¤±è´¥: {e}", exc_info=True)
            _record_task_metrics(task_name, "error", duration)
            # æ³¨æ„ï¼šcheck_expired_coupons å†…éƒ¨å·²ç»æœ‰ commitï¼Œå¦‚æœå‡ºé”™ä¼šåœ¨ commit ä¹‹å‰
            # è¿™é‡Œå°è¯• rollbackï¼Œä½†å¦‚æœå·²ç» commit ä¼šå¤±è´¥ï¼ˆå¿½ç•¥å³å¯ï¼‰
            try:
                db.rollback()
            except Exception:
                pass  # å¦‚æœå·²ç» commit æˆ–è¿æ¥å·²å…³é—­ï¼Œå¿½ç•¥ rollback é”™è¯¯
            if self.request.retries < self.max_retries:
                logger.info(f"ä»»åŠ¡å°†é‡è¯• ({self.request.retries + 1}/{self.max_retries})")
                raise self.retry(exc=e)
            raise
        finally:
            db.close()
    
    @celery_app.task(
        name='app.celery_tasks.check_expired_invitation_codes_task',
        bind=True,
        max_retries=3,
        default_retry_delay=60
    )
    def check_expired_invitation_codes_task(self):
        """æ£€æŸ¥è¿‡æœŸé‚€è¯·ç  - Celeryä»»åŠ¡åŒ…è£…"""
        start_time = time.time()
        task_name = 'check_expired_invitation_codes_task'
        db = SessionLocal()
        try:
            check_expired_invitation_codes(db)
            duration = time.time() - start_time
            logger.info(f"æ£€æŸ¥è¿‡æœŸé‚€è¯·ç å®Œæˆ (è€—æ—¶: {duration:.2f}ç§’)")
            _record_task_metrics(task_name, "success", duration)
            return {"status": "success", "message": "Expired invitation codes checked"}
        except Exception as e:
            duration = time.time() - start_time
            logger.error(f"æ£€æŸ¥è¿‡æœŸé‚€è¯·ç å¤±è´¥: {e}", exc_info=True)
            _record_task_metrics(task_name, "error", duration)
            # æ³¨æ„ï¼šcheck_expired_invitation_codes å†…éƒ¨å·²ç»æœ‰ commitï¼Œå¦‚æœå‡ºé”™ä¼šåœ¨ commit ä¹‹å‰
            try:
                db.rollback()
            except Exception:
                pass  # å¦‚æœå·²ç» commit æˆ–è¿æ¥å·²å…³é—­ï¼Œå¿½ç•¥ rollback é”™è¯¯
            if self.request.retries < self.max_retries:
                logger.info(f"ä»»åŠ¡å°†é‡è¯• ({self.request.retries + 1}/{self.max_retries})")
                raise self.retry(exc=e)
            raise
        finally:
            db.close()
    
    @celery_app.task(
        name='app.celery_tasks.check_expired_points_task',
        bind=True,
        max_retries=3,
        default_retry_delay=60
    )
    def check_expired_points_task(self):
        """æ£€æŸ¥è¿‡æœŸç§¯åˆ† - Celeryä»»åŠ¡åŒ…è£…"""
        start_time = time.time()
        task_name = 'check_expired_points_task'
        db = SessionLocal()
        try:
            check_expired_points(db)
            duration = time.time() - start_time
            logger.info(f"æ£€æŸ¥è¿‡æœŸç§¯åˆ†å®Œæˆ (è€—æ—¶: {duration:.2f}ç§’)")
            _record_task_metrics(task_name, "success", duration)
            return {"status": "success", "message": "Expired points checked"}
        except Exception as e:
            duration = time.time() - start_time
            logger.error(f"æ£€æŸ¥è¿‡æœŸç§¯åˆ†å¤±è´¥: {e}", exc_info=True)
            _record_task_metrics(task_name, "error", duration)
            # æ³¨æ„ï¼šcheck_expired_points å†…éƒ¨å·²ç»æœ‰ commitï¼Œå¦‚æœå‡ºé”™ä¼šåœ¨ commit ä¹‹å‰
            try:
                db.rollback()
            except Exception:
                pass  # å¦‚æœå·²ç» commit æˆ–è¿æ¥å·²å…³é—­ï¼Œå¿½ç•¥ rollback é”™è¯¯
            if self.request.retries < self.max_retries:
                logger.info(f"ä»»åŠ¡å°†é‡è¯• ({self.request.retries + 1}/{self.max_retries})")
                raise self.retry(exc=e)
            raise
        finally:
            db.close()
    
    @celery_app.task(
        name='app.celery_tasks.check_expired_payment_tasks_task',
        bind=True,
        max_retries=3,
        default_retry_delay=60
    )
    def check_expired_payment_tasks_task(self):
        """æ£€æŸ¥å¹¶å–æ¶ˆæ”¯ä»˜è¿‡æœŸçš„ä»»åŠ¡ - Celeryä»»åŠ¡åŒ…è£…"""
        start_time = time.time()
        task_name = 'check_expired_payment_tasks_task'
        db = SessionLocal()
        try:
            cancelled_count = check_expired_payment_tasks(db)
            duration = time.time() - start_time
            logger.info(f"æ£€æŸ¥æ”¯ä»˜è¿‡æœŸä»»åŠ¡å®Œæˆï¼Œå–æ¶ˆäº† {cancelled_count} ä¸ªä»»åŠ¡ (è€—æ—¶: {duration:.2f}ç§’)")
            _record_task_metrics(task_name, "success", duration)
            return {"status": "success", "cancelled_count": cancelled_count}
        except Exception as e:
            duration = time.time() - start_time
            logger.error(f"æ£€æŸ¥æ”¯ä»˜è¿‡æœŸä»»åŠ¡å¤±è´¥: {e}", exc_info=True)
            _record_task_metrics(task_name, "error", duration)
            try:
                db.rollback()
            except Exception:
                pass
            if self.request.retries < self.max_retries:
                logger.info(f"ä»»åŠ¡å°†é‡è¯• ({self.request.retries + 1}/{self.max_retries})")
                raise self.retry(exc=e)
            raise
        finally:
            db.close()
    
    @celery_app.task(
        name='app.celery_tasks.auto_complete_expired_time_slot_tasks_task',
        bind=True,
        max_retries=3,
        default_retry_delay=60
    )
    def auto_complete_expired_time_slot_tasks_task(self):
        """è‡ªåŠ¨å®Œæˆå·²è¿‡æœŸæ—¶é—´æ®µçš„ä»»åŠ¡ - Celeryä»»åŠ¡åŒ…è£…"""
        start_time = time.time()
        task_name = 'auto_complete_expired_time_slot_tasks_task'
        logger.info(f"ğŸ”„ å¼€å§‹æ‰§è¡Œå®šæ—¶ä»»åŠ¡: {task_name}")
        db = SessionLocal()
        try:
            completed_count = auto_complete_expired_time_slot_tasks(db)
            duration = time.time() - start_time
            logger.info(f"âœ… è‡ªåŠ¨å®Œæˆè¿‡æœŸæ—¶é—´æ®µä»»åŠ¡æ‰§è¡Œå®Œæˆï¼Œå®Œæˆäº† {completed_count} ä¸ªä»»åŠ¡ (è€—æ—¶: {duration:.2f}ç§’)")
            _record_task_metrics(task_name, "success", duration)
            return {"status": "success", "message": f"Completed {completed_count} expired time slot tasks", "completed_count": completed_count}
        except Exception as e:
            duration = time.time() - start_time
            logger.error(f"è‡ªåŠ¨å®Œæˆè¿‡æœŸæ—¶é—´æ®µä»»åŠ¡å¤±è´¥: {e}", exc_info=True)
            _record_task_metrics(task_name, "error", duration)
            try:
                db.rollback()
            except Exception:
                pass
            if self.request.retries < self.max_retries:
                logger.info(f"ä»»åŠ¡å°†é‡è¯• ({self.request.retries + 1}/{self.max_retries})")
                raise self.retry(exc=e)
            raise
        finally:
            db.close()
    
    @celery_app.task(
        name='app.celery_tasks.process_pending_payment_transfers_task',
        bind=True,
        max_retries=3,
        default_retry_delay=60
    )
    def process_pending_payment_transfers_task(self):
        """å¤„ç†å¾…å¤„ç†çš„æ”¯ä»˜è½¬è´¦ - Celeryä»»åŠ¡åŒ…è£…"""
        start_time = time.time()
        task_name = 'process_pending_payment_transfers_task'
        logger.info(f"ğŸ”„ å¼€å§‹æ‰§è¡Œå®šæ—¶ä»»åŠ¡: {task_name}")
        db = SessionLocal()
        try:
            from app.payment_transfer_service import process_pending_transfers
            stats = process_pending_transfers(db)
            duration = time.time() - start_time
            logger.info(f"âœ… å¤„ç†å¾…å¤„ç†è½¬è´¦å®Œæˆ: å¤„ç†={stats['processed']}, æˆåŠŸ={stats['succeeded']}, å¤±è´¥={stats['failed']}, é‡è¯•ä¸­={stats['retrying']} (è€—æ—¶: {duration:.2f}ç§’)")
            _record_task_metrics(task_name, "success", duration)
            return {"status": "success", "stats": stats}
        except Exception as e:
            duration = time.time() - start_time
            logger.error(f"å¤„ç†å¾…å¤„ç†è½¬è´¦å¤±è´¥: {e}", exc_info=True)
            _record_task_metrics(task_name, "error", duration)
            try:
                db.rollback()
            except Exception:
                pass
            if self.request.retries < self.max_retries:
                logger.info(f"ä»»åŠ¡å°†é‡è¯• ({self.request.retries + 1}/{self.max_retries})")
                raise self.retry(exc=e)
            raise
        finally:
            db.close()
    
    @celery_app.task(
        name='app.celery_tasks.revert_unpaid_application_approvals_task',
        bind=True,
        max_retries=3,
        default_retry_delay=60
    )
    def revert_unpaid_application_approvals_task(self):
        """æ’¤é”€è¶…æ—¶æœªæ”¯ä»˜çš„ç”³è¯·æ‰¹å‡† - Celeryä»»åŠ¡åŒ…è£…ï¼ˆæ¯1å°æ—¶æ‰§è¡Œï¼‰"""
        start_time = time.time()
        task_name = 'revert_unpaid_application_approvals_task'
        logger.info(f"ğŸ”„ å¼€å§‹æ‰§è¡Œå®šæ—¶ä»»åŠ¡: {task_name}")
        db = SessionLocal()
        try:
            reverted_count = revert_unpaid_application_approvals(db)
            duration = time.time() - start_time
            logger.info(f"âœ… æ’¤é”€è¶…æ—¶æœªæ”¯ä»˜ç”³è¯·æ‰¹å‡†æ‰§è¡Œå®Œæˆï¼Œæ’¤é”€äº† {reverted_count} ä¸ªä»»åŠ¡ (è€—æ—¶: {duration:.2f}ç§’)")
            _record_task_metrics(task_name, "success", duration)
            return {"status": "success", "message": f"Reverted {reverted_count} unpaid application approvals", "reverted_count": reverted_count}
        except Exception as e:
            duration = time.time() - start_time
            logger.error(f"æ’¤é”€è¶…æ—¶æœªæ”¯ä»˜ç”³è¯·æ‰¹å‡†å¤±è´¥: {e}", exc_info=True)
            _record_task_metrics(task_name, "error", duration)
            try:
                db.rollback()
            except Exception:
                pass
            if self.request.retries < self.max_retries:
                logger.info(f"ä»»åŠ¡å°†é‡è¯• ({self.request.retries + 1}/{self.max_retries})")
                raise self.retry(exc=e)
            raise
        finally:
            db.close()
    
    @celery_app.task(
        name='app.celery_tasks.check_transfer_timeout_task',
        bind=True,
        max_retries=3,
        default_retry_delay=60
    )
    def check_transfer_timeout_task(self):
        """æ£€æŸ¥è½¬è´¦è¶…æ—¶ - Celeryä»»åŠ¡åŒ…è£…"""
        start_time = time.time()
        task_name = 'check_transfer_timeout_task'
        logger.info(f"ğŸ”„ å¼€å§‹æ‰§è¡Œå®šæ—¶ä»»åŠ¡: {task_name}")
        db = SessionLocal()
        try:
            from app.payment_transfer_service import check_transfer_timeout
            stats = check_transfer_timeout(db, timeout_hours=24)
            duration = time.time() - start_time
            logger.info(f"âœ… è½¬è´¦è¶…æ—¶æ£€æŸ¥å®Œæˆ: æ£€æŸ¥={stats['checked']}, è¶…æ—¶={stats['timeout']}, æ›´æ–°={stats['updated']} (è€—æ—¶: {duration:.2f}ç§’)")
            _record_task_metrics(task_name, "success", duration)
            return {"status": "success", "stats": stats}
        except Exception as e:
            duration = time.time() - start_time
            logger.error(f"æ£€æŸ¥è½¬è´¦è¶…æ—¶å¤±è´¥: {e}", exc_info=True)
            _record_task_metrics(task_name, "error", duration)
            try:
                db.rollback()
            except Exception:
                pass
            if self.request.retries < self.max_retries:
                logger.info(f"ä»»åŠ¡å°†é‡è¯• ({self.request.retries + 1}/{self.max_retries})")
                raise self.retry(exc=e)
            raise
        finally:
            db.close()
    
    @celery_app.task(
        name='app.celery_tasks.process_expired_verifications_task',
        bind=True,
        max_retries=3,
        default_retry_delay=60
    )
    def process_expired_verifications_task(self):
        """å¤„ç†è¿‡æœŸè®¤è¯ - Celeryä»»åŠ¡åŒ…è£…"""
        start_time = time.time()
        task_name = 'process_expired_verifications_task'
        logger.info(f"ğŸ”„ å¼€å§‹æ‰§è¡Œå®šæ—¶ä»»åŠ¡: {task_name}")
        db = SessionLocal()
        try:
            process_expired_verifications(db)
            duration = time.time() - start_time
            logger.info(f"âœ… å¤„ç†è¿‡æœŸè®¤è¯å®Œæˆ (è€—æ—¶: {duration:.2f}ç§’)")
            _record_task_metrics(task_name, "success", duration)
            return {"status": "success", "message": "Processed expired verifications"}
        except Exception as e:
            duration = time.time() - start_time
            logger.error(f"å¤„ç†è¿‡æœŸè®¤è¯å¤±è´¥: {e}", exc_info=True)
            _record_task_metrics(task_name, "error", duration)
            try:
                db.rollback()
            except Exception:
                pass
            if self.request.retries < self.max_retries:
                logger.info(f"ä»»åŠ¡å°†é‡è¯• ({self.request.retries + 1}/{self.max_retries})")
                raise self.retry(exc=e)
            raise
        finally:
            db.close()
    
    @celery_app.task(
        name='app.celery_tasks.check_and_end_activities_task',
        bind=True,
        max_retries=2,  # æ´»åŠ¨ç»“æŸä»»åŠ¡é‡è¯•æ¬¡æ•°è¾ƒå°‘
        default_retry_delay=120  # é‡è¯•å»¶è¿Ÿ2åˆ†é’Ÿ
    )
    def check_and_end_activities_task(self):
        """æ£€æŸ¥å¹¶ç»“æŸæ´»åŠ¨ - Celeryä»»åŠ¡åŒ…è£…"""
        start_time = time.time()
        task_name = 'check_and_end_activities_task'
        # æ³¨æ„ï¼šcheck_and_end_activities_sync å†…éƒ¨ä½¿ç”¨å¼‚æ­¥æ•°æ®åº“ä¼šè¯ï¼Œä¸ä¾èµ–ä¼ å…¥çš„ db
        # ä½†ä¸ºäº†ä¿æŒæ¥å£ä¸€è‡´æ€§ï¼Œä»ç„¶ä¼ å…¥ dbï¼ˆè™½ç„¶ä¸ä¼šè¢«ä½¿ç”¨ï¼‰
        db = SessionLocal()
        try:
            ended_count = check_and_end_activities_sync(db)
            duration = time.time() - start_time
            logger.info(f"æ£€æŸ¥å¹¶ç»“æŸæ´»åŠ¨å®Œæˆï¼Œç»“æŸäº† {ended_count} ä¸ªæ´»åŠ¨ (è€—æ—¶: {duration:.2f}ç§’)")
            _record_task_metrics(task_name, "success", duration)
            return {"status": "success", "message": f"Ended {ended_count} activities", "ended_count": ended_count}
        except Exception as e:
            duration = time.time() - start_time
            logger.error(f"æ£€æŸ¥å¹¶ç»“æŸæ´»åŠ¨å¤±è´¥: {e}", exc_info=True)
            _record_task_metrics(task_name, "error", duration)
            # check_and_end_activities_sync å†…éƒ¨ä½¿ç”¨å¼‚æ­¥ä¼šè¯ï¼Œä¸ä¾èµ–åŒæ­¥ db
            # è¿™é‡Œ rollback ä¸»è¦æ˜¯ä¸ºäº†æ¸…ç†åŒæ­¥ä¼šè¯çŠ¶æ€
            try:
                db.rollback()
            except Exception:
                pass  # å¦‚æœè¿æ¥å·²å…³é—­ï¼Œå¿½ç•¥ rollback é”™è¯¯
            if self.request.retries < self.max_retries:
                logger.info(f"ä»»åŠ¡å°†é‡è¯• ({self.request.retries + 1}/{self.max_retries})")
                raise self.retry(exc=e)
            raise
        finally:
            db.close()
    
    @celery_app.task(
        name='app.celery_tasks.update_all_users_statistics_task',
        bind=True,
        max_retries=2,
        default_retry_delay=60
    )
    def update_all_users_statistics_task(self):
        """æ›´æ–°æ‰€æœ‰ç”¨æˆ·ç»Ÿè®¡ä¿¡æ¯ - Celeryä»»åŠ¡åŒ…è£…ï¼ˆå¸¦åˆ†å¸ƒå¼é”ï¼Œé¿å…å è·‘ï¼‰"""
        lock_key = "scheduled:update_all_users_statistics:lock"
        lock_ttl = 600  # 10åˆ†é’Ÿï¼ˆä»»åŠ¡æ‰§è¡Œå‘¨æœŸï¼‰
        
        # å°è¯•è·å–åˆ†å¸ƒå¼é”
        if not get_redis_distributed_lock(lock_key, lock_ttl):
            logger.warning("æ›´æ–°ç”¨æˆ·ç»Ÿè®¡ä¿¡æ¯ä»»åŠ¡æ­£åœ¨æ‰§è¡Œä¸­ï¼Œè·³è¿‡æœ¬æ¬¡è°ƒåº¦")
            return {"status": "skipped", "reason": "previous_task_running"}
        
        start_time = time.time()
        task_name = 'update_all_users_statistics_task'
        try:
            update_all_users_statistics()
            duration = time.time() - start_time
            logger.info(f"æ›´æ–°æ‰€æœ‰ç”¨æˆ·ç»Ÿè®¡ä¿¡æ¯å®Œæˆ (è€—æ—¶: {duration:.2f}ç§’)")
            _record_task_metrics(task_name, "success", duration)
            return {"status": "success", "message": "User statistics updated"}
        except Exception as e:
            duration = time.time() - start_time
            logger.error(f"æ›´æ–°æ‰€æœ‰ç”¨æˆ·ç»Ÿè®¡ä¿¡æ¯å¤±è´¥: {e}", exc_info=True)
            _record_task_metrics(task_name, "error", duration)
            if self.request.retries < self.max_retries:
                logger.info(f"ä»»åŠ¡å°†é‡è¯• ({self.request.retries + 1}/{self.max_retries})")
                raise self.retry(exc=e)
            raise
        finally:
            # é‡Šæ”¾é”
            release_redis_distributed_lock(lock_key)
    
        start_time = time.time()
        task_name = 'update_all_users_statistics_task'
        try:
            update_all_users_statistics()
            duration = time.time() - start_time
            logger.info(f"æ›´æ–°æ‰€æœ‰ç”¨æˆ·ç»Ÿè®¡ä¿¡æ¯å®Œæˆ (è€—æ—¶: {duration:.2f}ç§’)")
            _record_task_metrics(task_name, "success", duration)
            return {"status": "success", "message": "User statistics updated"}
        except Exception as e:
            duration = time.time() - start_time
            logger.error(f"æ›´æ–°æ‰€æœ‰ç”¨æˆ·ç»Ÿè®¡ä¿¡æ¯å¤±è´¥: {e}", exc_info=True)
            _record_task_metrics(task_name, "error", duration)
            if self.request.retries < self.max_retries:
                logger.info(f"ä»»åŠ¡å°†é‡è¯• ({self.request.retries + 1}/{self.max_retries})")
                raise self.retry(exc=e)
            raise
    
    @celery_app.task(
        name='app.celery_tasks.update_featured_task_experts_response_time_task',
        bind=True,
        max_retries=2,
        default_retry_delay=300  # é‡è¯•å»¶è¿Ÿ5åˆ†é’Ÿ
    )
    def update_featured_task_experts_response_time_task(self):
        """æ›´æ–°ç‰¹å¾ä»»åŠ¡è¾¾äººçš„å“åº”æ—¶é—´ - Celeryä»»åŠ¡åŒ…è£…ï¼ˆæ¯å¤©å‡Œæ™¨3ç‚¹æ‰§è¡Œï¼‰"""
        start_time = time.time()
        task_name = 'update_featured_task_experts_response_time_task'
        # æ³¨æ„ï¼šæ—¶é—´æ£€æŸ¥ç”± Celery Beat çš„ crontab è°ƒåº¦å®Œæˆï¼Œè¿™é‡Œä¸éœ€è¦å†æ£€æŸ¥
        try:
            updated_count = update_all_featured_task_experts_response_time()
            duration = time.time() - start_time
            logger.info(f"æ›´æ–°ç‰¹å¾ä»»åŠ¡è¾¾äººå“åº”æ—¶é—´å®Œæˆï¼Œæ›´æ–°äº† {updated_count} ä¸ªè¾¾äºº (è€—æ—¶: {duration:.2f}ç§’)")
            _record_task_metrics(task_name, "success", duration)
            return {"status": "success", "message": f"Updated {updated_count} featured task experts response time", "updated_count": updated_count}
        except Exception as e:
            duration = time.time() - start_time
            logger.error(f"æ›´æ–°ç‰¹å¾ä»»åŠ¡è¾¾äººå“åº”æ—¶é—´å¤±è´¥: {e}", exc_info=True)
            _record_task_metrics(task_name, "error", duration)
            if self.request.retries < self.max_retries:
                logger.info(f"ä»»åŠ¡å°†é‡è¯• ({self.request.retries + 1}/{self.max_retries})")
                raise self.retry(exc=e)
            raise
    
    @celery_app.task(
        name='app.celery_tasks.cleanup_long_inactive_chats_task',
        bind=True,
        max_retries=2,
        default_retry_delay=300  # é‡è¯•å»¶è¿Ÿ5åˆ†é’Ÿ
    )
    def cleanup_long_inactive_chats_task(self):
        """æ¸…ç†é•¿æœŸæ— æ´»åŠ¨å¯¹è¯ - Celeryä»»åŠ¡åŒ…è£…ï¼ˆæ¯å¤©å‡Œæ™¨2ç‚¹æ‰§è¡Œï¼‰"""
        start_time = time.time()
        task_name = 'cleanup_long_inactive_chats_task'
        from app.customer_service_tasks import cleanup_long_inactive_chats
        # æ³¨æ„ï¼šæ—¶é—´æ£€æŸ¥ç”± Celery Beat çš„ crontab è°ƒåº¦å®Œæˆï¼Œè¿™é‡Œä¸éœ€è¦å†æ£€æŸ¥
        db = SessionLocal()
        try:
            result = cleanup_long_inactive_chats(db, inactive_days=30)
            duration = time.time() - start_time
            logger.info(f"æ¸…ç†é•¿æœŸæ— æ´»åŠ¨å¯¹è¯å®Œæˆ (è€—æ—¶: {duration:.2f}ç§’)")
            _record_task_metrics(task_name, "success", duration)
            return {"status": "success", "message": "Long inactive chats cleaned", "result": result}
        except Exception as e:
            duration = time.time() - start_time
            logger.error(f"æ¸…ç†é•¿æœŸæ— æ´»åŠ¨å¯¹è¯å¤±è´¥: {e}", exc_info=True)
            _record_task_metrics(task_name, "error", duration)
            # ä»»åŠ¡å‡½æ•°å†…éƒ¨å·²ç»å¤„ç†äº† rollbackï¼Œè¿™é‡Œåªéœ€è¦è®°å½•é”™è¯¯
            if self.request.retries < self.max_retries:
                logger.info(f"ä»»åŠ¡å°†é‡è¯• ({self.request.retries + 1}/{self.max_retries})")
                raise self.retry(exc=e)
            raise
        finally:
            db.close()
    
    @celery_app.task(
        name='app.celery_tasks.sync_forum_view_counts_task',
        bind=True,
        max_retries=2,
        default_retry_delay=300  # é‡è¯•å»¶è¿Ÿ5åˆ†é’Ÿ
    )
    def sync_forum_view_counts_task(self):
        """åŒæ­¥è®ºå›å¸–å­æµè§ˆæ•°ä» Redis åˆ°æ•°æ®åº“ - Celeryä»»åŠ¡åŒ…è£…ï¼ˆæ¯5åˆ†é’Ÿæ‰§è¡Œï¼‰"""
        logger.info("ğŸ”„ å¼€å§‹æ‰§è¡ŒåŒæ­¥è®ºå›æµè§ˆé‡ä»»åŠ¡")
        start_time = time.time()
        task_name = 'sync_forum_view_counts_task'
        lock_key = 'forum:sync_view_counts:lock'
        
        # è·å–åˆ†å¸ƒå¼é”ï¼Œé˜²æ­¢å¤šå®ä¾‹é‡å¤æ‰§è¡Œ
        if not get_redis_distributed_lock(lock_key, lock_ttl=600):  # é”10åˆ†é’Ÿ
            logger.warning("âš ï¸ åŒæ­¥è®ºå›æµè§ˆæ•°ä»»åŠ¡å·²åœ¨å…¶ä»–å®ä¾‹æ‰§è¡Œï¼Œè·³è¿‡æœ¬æ¬¡æ‰§è¡Œ")
            return {"status": "skipped", "message": "Task already running in another instance"}
        
        try:
            from app.redis_cache import get_redis_client
            from app.database import SessionLocal
            from app.models import ForumPost
            from sqlalchemy import update
            
            redis_client = get_redis_client()
            if not redis_client:
                logger.warning("Redis ä¸å¯ç”¨ï¼Œæ— æ³•åŒæ­¥è®ºå›æµè§ˆæ•°")
                return {"status": "skipped", "message": "Redis not available"}
            
            db = SessionLocal()
            try:
                # è·å–æ‰€æœ‰è®ºå›æµè§ˆæ•°çš„ Redis keyï¼ˆä½¿ç”¨ SCAN æ›¿ä»£ KEYSï¼‰
                from app.redis_utils import scan_keys
                pattern = "forum:post:view_count:*"
                keys = scan_keys(redis_client, pattern)
                
                if not keys:
                    logger.info("â„¹ï¸ æ²¡æœ‰éœ€è¦åŒæ­¥çš„è®ºå›æµè§ˆæ•°ï¼ˆRedis ä¸­æ²¡æœ‰ forum:post:view_count:* keysï¼‰")
                    return {"status": "success", "message": "No view counts to sync", "synced_count": 0}
                
                synced_count = 0
                failed_count = 0
                synced_keys = []  # è®°å½•æˆåŠŸåŒæ­¥çš„ keysï¼Œç”¨äºåç»­åˆ é™¤
                
                for key in keys:
                    try:
                        # å¤„ç† bytes ç±»å‹çš„ keyï¼ˆRedis äºŒè¿›åˆ¶æ¨¡å¼ï¼‰
                        if isinstance(key, bytes):
                            key_str = key.decode('utf-8')
                        else:
                            key_str = str(key)
                        
                        # ä» key ä¸­æå– post_id
                        post_id = int(key_str.split(":")[-1])
                        
                        # è·å– Redis ä¸­çš„å¢é‡
                        redis_increment = redis_client.get(key)
                        if redis_increment:
                            # å¤„ç† bytes ç±»å‹çš„å€¼
                            if isinstance(redis_increment, bytes):
                                increment = int(redis_increment.decode('utf-8'))
                            else:
                                increment = int(redis_increment)
                            
                            if increment > 0:
                                # æ›´æ–°æ•°æ®åº“ä¸­çš„æµè§ˆæ•°
                                db.execute(
                                    update(ForumPost)
                                    .where(ForumPost.id == post_id)
                                    .values(view_count=ForumPost.view_count + increment)
                                )
                                synced_count += 1
                                synced_keys.append(key)  # è®°å½•æˆåŠŸåŒæ­¥çš„ key
                    except (ValueError, TypeError) as e:
                        logger.warning(f"å¤„ç†æµè§ˆæ•° key {key} æ—¶å‡ºé”™: {e}")
                        failed_count += 1
                        continue
                    except Exception as e:
                        logger.error(f"åŒæ­¥å¸–å­ {key} æµè§ˆæ•°å¤±è´¥: {e}")
                        failed_count += 1
                        continue
                
                # å…ˆæäº¤æ•°æ®åº“äº‹åŠ¡
                db.commit()
                
                # æ•°æ®åº“æäº¤æˆåŠŸåï¼Œåˆ é™¤å·²åŒæ­¥çš„ Redis keys
                deleted_count = 0
                for key in synced_keys:
                    try:
                        redis_client.delete(key)
                        deleted_count += 1
                    except Exception as e:
                        logger.warning(f"åˆ é™¤ Redis key {key} å¤±è´¥: {e}")
                        # ç»§ç»­å¤„ç†å…¶ä»– key
                
                duration = time.time() - start_time
                if failed_count > 0:
                    logger.warning(f"âœ… åŒæ­¥è®ºå›æµè§ˆæ•°å®Œæˆï¼ŒåŒæ­¥äº† {synced_count} ä¸ªå¸–å­ï¼Œå¤±è´¥ {failed_count} ä¸ª (è€—æ—¶: {duration:.2f}ç§’)")
                else:
                    logger.info(f"âœ… åŒæ­¥è®ºå›æµè§ˆæ•°å®Œæˆï¼ŒåŒæ­¥äº† {synced_count} ä¸ªå¸–å­ (è€—æ—¶: {duration:.2f}ç§’)")
                _record_task_metrics(task_name, "success", duration)
                return {
                    "status": "success", 
                    "message": f"Synced {synced_count} post view counts", 
                    "synced_count": synced_count,
                    "failed_count": failed_count,
                    "deleted_keys": deleted_count
                }
            finally:
                db.close()
                # é‡Šæ”¾åˆ†å¸ƒå¼é”
                release_redis_distributed_lock(lock_key)
        except Exception as e:
            duration = time.time() - start_time
            logger.error(f"åŒæ­¥è®ºå›æµè§ˆæ•°å¤±è´¥: {e}", exc_info=True)
            _record_task_metrics(task_name, "error", duration)
            # é‡Šæ”¾åˆ†å¸ƒå¼é”
            release_redis_distributed_lock(lock_key)
            if self.request.retries < self.max_retries:
                logger.info(f"ä»»åŠ¡å°†é‡è¯• ({self.request.retries + 1}/{self.max_retries})")
                raise self.retry(exc=e)
            raise

    @celery_app.task(
        name='app.celery_tasks.sync_leaderboard_view_counts_task',
        bind=True,
        max_retries=2,
        default_retry_delay=300  # é‡è¯•å»¶è¿Ÿ5åˆ†é’Ÿ
    )
    def sync_leaderboard_view_counts_task(self):
        """åŒæ­¥æ¦œå•æµè§ˆæ•°ä» Redis åˆ°æ•°æ®åº“ - Celeryä»»åŠ¡åŒ…è£…ï¼ˆæ¯5åˆ†é’Ÿæ‰§è¡Œï¼‰"""
        logger.info("ğŸ”„ å¼€å§‹æ‰§è¡ŒåŒæ­¥æ¦œå•æµè§ˆé‡ä»»åŠ¡")
        start_time = time.time()
        task_name = 'sync_leaderboard_view_counts_task'
        lock_key = 'leaderboard:sync_view_counts:lock'
        
        # è·å–åˆ†å¸ƒå¼é”ï¼Œé˜²æ­¢å¤šå®ä¾‹é‡å¤æ‰§è¡Œ
        if not get_redis_distributed_lock(lock_key, lock_ttl=600):  # é”10åˆ†é’Ÿ
            logger.warning("âš ï¸ åŒæ­¥æ¦œå•æµè§ˆæ•°ä»»åŠ¡å·²åœ¨å…¶ä»–å®ä¾‹æ‰§è¡Œï¼Œè·³è¿‡æœ¬æ¬¡æ‰§è¡Œ")
            return {"status": "skipped", "message": "Task already running in another instance"}
        
        try:
            from app.redis_cache import get_redis_client
            from app.database import SessionLocal
            from app.models import CustomLeaderboard
            from sqlalchemy import update
            
            redis_client = get_redis_client()
            if not redis_client:
                logger.warning("Redis ä¸å¯ç”¨ï¼Œæ— æ³•åŒæ­¥æ¦œå•æµè§ˆæ•°")
                return {"status": "skipped", "message": "Redis not available"}
            
            db = SessionLocal()
            try:
                # è·å–æ‰€æœ‰æ¦œå•æµè§ˆæ•°çš„ Redis keyï¼ˆä½¿ç”¨ SCAN æ›¿ä»£ KEYSï¼‰
                from app.redis_utils import scan_keys
                pattern = "leaderboard:view_count:*"
                keys = scan_keys(redis_client, pattern)
                
                if not keys:
                    logger.info("â„¹ï¸ æ²¡æœ‰éœ€è¦åŒæ­¥çš„æ¦œå•æµè§ˆæ•°ï¼ˆRedis ä¸­æ²¡æœ‰ leaderboard:view_count:* keysï¼‰")
                    return {"status": "success", "message": "No view counts to sync", "synced_count": 0}
                
                synced_count = 0
                failed_count = 0
                synced_keys = []  # è®°å½•æˆåŠŸåŒæ­¥çš„ keysï¼Œç”¨äºåç»­åˆ é™¤
                
                for key in keys:
                    try:
                        # å¤„ç† bytes ç±»å‹çš„ keyï¼ˆRedis äºŒè¿›åˆ¶æ¨¡å¼ï¼‰
                        if isinstance(key, bytes):
                            key_str = key.decode('utf-8')
                        else:
                            key_str = str(key)
                        
                        # ä» key ä¸­æå– leaderboard_id
                        leaderboard_id = int(key_str.split(":")[-1])
                        
                        # è·å– Redis ä¸­çš„å¢é‡
                        redis_increment = redis_client.get(key)
                        if redis_increment:
                            # å¤„ç† bytes ç±»å‹çš„å€¼
                            if isinstance(redis_increment, bytes):
                                increment = int(redis_increment.decode('utf-8'))
                            else:
                                increment = int(redis_increment)
                            
                            if increment > 0:
                                # æ›´æ–°æ•°æ®åº“ä¸­çš„æµè§ˆæ•°
                                db.execute(
                                    update(CustomLeaderboard)
                                    .where(CustomLeaderboard.id == leaderboard_id)
                                    .values(view_count=CustomLeaderboard.view_count + increment)
                                )
                                synced_count += 1
                                synced_keys.append(key)  # è®°å½•æˆåŠŸåŒæ­¥çš„ key
                    except (ValueError, TypeError) as e:
                        logger.warning(f"å¤„ç†æ¦œå•æµè§ˆæ•° key {key} æ—¶å‡ºé”™: {e}")
                        failed_count += 1
                        continue
                    except Exception as e:
                        logger.error(f"åŒæ­¥æ¦œå• {key} æµè§ˆæ•°å¤±è´¥: {e}")
                        failed_count += 1
                        continue
                
                # å…ˆæäº¤æ•°æ®åº“äº‹åŠ¡
                db.commit()
                
                # æ•°æ®åº“æäº¤æˆåŠŸåï¼Œåˆ é™¤å·²åŒæ­¥çš„ Redis keys
                deleted_count = 0
                for key in synced_keys:
                    try:
                        redis_client.delete(key)
                        deleted_count += 1
                    except Exception as e:
                        logger.warning(f"åˆ é™¤ Redis key {key} å¤±è´¥: {e}")
                        # ç»§ç»­å¤„ç†å…¶ä»– key
                
                duration = time.time() - start_time
                if failed_count > 0:
                    logger.warning(f"âœ… åŒæ­¥æ¦œå•æµè§ˆæ•°å®Œæˆï¼ŒåŒæ­¥äº† {synced_count} ä¸ªæ¦œå•ï¼Œå¤±è´¥ {failed_count} ä¸ª (è€—æ—¶: {duration:.2f}ç§’)")
                else:
                    logger.info(f"âœ… åŒæ­¥æ¦œå•æµè§ˆæ•°å®Œæˆï¼ŒåŒæ­¥äº† {synced_count} ä¸ªæ¦œå• (è€—æ—¶: {duration:.2f}ç§’)")
                _record_task_metrics(task_name, "success", duration)
                return {
                    "status": "success", 
                    "message": f"Synced {synced_count} leaderboard view counts", 
                    "synced_count": synced_count,
                    "failed_count": failed_count,
                    "deleted_keys": deleted_count
                }
            finally:
                db.close()
                # é‡Šæ”¾åˆ†å¸ƒå¼é”
                release_redis_distributed_lock(lock_key)
        except Exception as e:
            duration = time.time() - start_time
            logger.error(f"åŒæ­¥æ¦œå•æµè§ˆæ•°ä»»åŠ¡å¤±è´¥: {e}", exc_info=True)
            _record_task_metrics(task_name, "error", duration)
            # é‡Šæ”¾åˆ†å¸ƒå¼é”
            release_redis_distributed_lock(lock_key)
            if self.request.retries < self.max_retries:
                logger.info(f"ä»»åŠ¡å°†é‡è¯• ({self.request.retries + 1}/{self.max_retries})")
                raise self.retry(exc=e)
            raise

    @celery_app.task(
        name='app.celery_tasks.check_expired_vip_subscriptions_task',
        bind=True,
        max_retries=3,
        default_retry_delay=300  # é‡è¯•å»¶è¿Ÿ5åˆ†é’Ÿ
    )
    def check_expired_vip_subscriptions_task(self):
        """æ£€æŸ¥å¹¶æ›´æ–°è¿‡æœŸçš„VIPè®¢é˜… - Celeryä»»åŠ¡åŒ…è£…ï¼ˆæ¯1å°æ—¶æ‰§è¡Œï¼‰"""
        start_time = time.time()
        task_name = 'check_expired_vip_subscriptions_task'
        db = SessionLocal()
        try:
            updated_count = check_and_update_expired_subscriptions(db)
            duration = time.time() - start_time
            logger.info(f"VIPè®¢é˜…è¿‡æœŸæ£€æŸ¥å®Œæˆ: æ›´æ–°äº† {updated_count} ä¸ªè¿‡æœŸè®¢é˜… (è€—æ—¶: {duration:.2f}ç§’)")
            _record_task_metrics(task_name, "success", duration)
            return {
                "status": "success",
                "message": f"Updated {updated_count} expired subscriptions",
                "updated_count": updated_count
            }
        except Exception as e:
            duration = time.time() - start_time
            logger.error(f"VIPè®¢é˜…è¿‡æœŸæ£€æŸ¥å¤±è´¥: {e}", exc_info=True)
            _record_task_metrics(task_name, "error", duration)
            try:
                db.rollback()
            except Exception:
                pass
            if self.request.retries < self.max_retries:
                logger.info(f"ä»»åŠ¡å°†é‡è¯• ({self.request.retries + 1}/{self.max_retries})")
                raise self.retry(exc=e)
            raise
        finally:
            db.close()

