"""
è‡ªåŠ¨æ£€æµ‹å¹¶ä¿®å¤è¿ç§»çŠ¶æ€ä¸ä¸€è‡´çš„é—®é¢˜

åœ¨åº”ç”¨å¯åŠ¨æ—¶è‡ªåŠ¨è¿è¡Œï¼Œé€šè¿‡ç¯å¢ƒå˜é‡æ§åˆ¶ï¼š
- RESET_MIGRATIONS=true: æ¸…ç©ºè¿ç§»è®°å½•ï¼Œé‡æ–°æ‰§è¡Œæ‰€æœ‰è¿ç§»
- FIX_MIGRATIONS=true: æ™ºèƒ½æ£€æµ‹å¹¶ä¿®å¤ï¼ˆæ¨èï¼‰
- DROP_ALL_TABLES=true: åˆ é™¤æ‰€æœ‰æ•°æ®åº“è¡¨å¹¶é‡æ–°åˆ›å»ºï¼ˆâš ï¸ å±é™©ï¼šä¼šæ¸…é™¤æ‰€æœ‰æ•°æ®ï¼‰

æ³¨æ„ï¼šDROP_ALL_TABLES éœ€è¦ä¸ RESET_MIGRATIONS æˆ– FIX_MIGRATIONS ä¸€èµ·ä½¿ç”¨
"""

import os
import logging
from sqlalchemy import text, inspect
from sqlalchemy.engine import Engine

logger = logging.getLogger(__name__)


def check_migration_consistency(engine: Engine) -> dict:
    """
    æ£€æŸ¥è¿ç§»çŠ¶æ€ä¸€è‡´æ€§

    Returns:
        {
            'has_schema_migrations': bool,
            'migration_count': int,
            'table_count': int,
            'has_critical_tables': bool,
            'missing_tables': list,
            'needs_fix': bool
        }
    """
    inspector = inspect(engine)
    all_tables = inspector.get_table_names()

    # å…³é”®è¡¨åˆ—è¡¨
    critical_tables = [
        'users', 'tasks', 'universities', 'notifications',
        'messages', 'conversations', 'reviews'
    ]

    missing_tables = [t for t in critical_tables if t not in all_tables]
    has_critical_tables = len(missing_tables) == 0

    result = {
        'has_schema_migrations': 'schema_migrations' in all_tables,
        'migration_count': 0,
        'table_count': len(all_tables),
        'has_critical_tables': has_critical_tables,
        'missing_tables': missing_tables,
        'needs_fix': False
    }

    # æ£€æŸ¥è¿ç§»è®°å½•æ•°
    if result['has_schema_migrations']:
        try:
            with engine.connect() as conn:
                res = conn.execute(text("SELECT COUNT(*) FROM schema_migrations"))
                result['migration_count'] = res.scalar()
        except Exception as e:
            logger.warning(f"æ— æ³•è¯»å–è¿ç§»è®°å½•: {e}")

    # åˆ¤æ–­æ˜¯å¦éœ€è¦ä¿®å¤
    # å¦‚æœæœ‰è¿ç§»è®°å½•ä½†ç¼ºå°‘å…³é”®è¡¨ï¼Œè¯´æ˜çŠ¶æ€ä¸ä¸€è‡´
    if result['migration_count'] > 0 and not has_critical_tables:
        result['needs_fix'] = True
        logger.warning(f"âš ï¸  æ£€æµ‹åˆ°çŠ¶æ€ä¸ä¸€è‡´: æœ‰ {result['migration_count']} æ¡è¿ç§»è®°å½•ï¼Œä½†ç¼ºå°‘ {len(missing_tables)} ä¸ªå…³é”®è¡¨")

    return result


def reset_migration_records(engine: Engine, drop_tables: bool = False):
    """
    æ¸…ç©ºè¿ç§»è®°å½•è¡¨ï¼Œå¯é€‰æ‹©æ˜¯å¦åŒæ—¶åˆ é™¤æ‰€æœ‰è¡¨

    Args:
        engine: æ•°æ®åº“å¼•æ“
        drop_tables: æ˜¯å¦åŒæ—¶åˆ é™¤æ‰€æœ‰æ•°æ®åº“è¡¨ï¼ˆç”¨äºå®Œå…¨é‡ç½®ï¼‰
    """
    try:
        with engine.connect() as conn:
            # æ£€æŸ¥è¡¨æ˜¯å¦å­˜åœ¨
            result = conn.execute(text("""
                SELECT EXISTS (
                    SELECT FROM information_schema.tables
                    WHERE table_name = 'schema_migrations'
                )
            """))

            if result.scalar():
                # å…ˆæŸ¥çœ‹æœ‰å¤šå°‘è®°å½•
                count_result = conn.execute(text("SELECT COUNT(*) FROM schema_migrations"))
                count = count_result.scalar()

                # æ¸…ç©ºè¡¨
                conn.execute(text("TRUNCATE TABLE schema_migrations"))
                conn.commit()

                logger.info(f"âœ… å·²æ¸…ç©º schema_migrations è¡¨ ({count} æ¡è®°å½•)")
            else:
                logger.info("â„¹ï¸  schema_migrations è¡¨ä¸å­˜åœ¨ï¼Œæ— éœ€æ¸…ç©º")

            # å¦‚æœéœ€è¦åˆ é™¤æ‰€æœ‰è¡¨ï¼ˆå®Œå…¨é‡ç½®ï¼‰
            if drop_tables:
                logger.warning("ğŸ—‘ï¸  å¼€å§‹åˆ é™¤æ‰€æœ‰æ•°æ®åº“å¯¹è±¡...")

                # å…ˆåˆ é™¤æ‰€æœ‰å‡½æ•°å’Œè§¦å‘å™¨ï¼ˆé¿å…ä¾èµ–é—®é¢˜ï¼‰
                try:
                    # è·å–æ‰€æœ‰è‡ªå®šä¹‰å‡½æ•°
                    functions_result = conn.execute(text("""
                        SELECT proname, oidvectortypes(proargtypes) as argtypes
                        FROM pg_proc INNER JOIN pg_namespace ns ON (pg_proc.pronamespace = ns.oid)
                        WHERE ns.nspname = 'public' AND prokind = 'f'
                    """))
                    functions = functions_result.fetchall()

                    for func_name, arg_types in functions:
                        try:
                            # åˆ é™¤å‡½æ•°ï¼ˆåŒ…æ‹¬æ‰€æœ‰é‡è½½ç‰ˆæœ¬ï¼‰
                            conn.execute(text(f'DROP FUNCTION IF EXISTS "{func_name}"({arg_types}) CASCADE'))
                            logger.debug(f"  å·²åˆ é™¤å‡½æ•°: {func_name}({arg_types})")
                        except Exception as e:
                            logger.debug(f"  åˆ é™¤å‡½æ•°å¤±è´¥ï¼ˆå¯èƒ½ä¸å­˜åœ¨ï¼‰: {e}")

                    conn.commit()
                except Exception as e:
                    logger.warning(f"åˆ é™¤å‡½æ•°æ—¶å‡ºé”™ï¼ˆç»§ç»­ï¼‰: {e}")
                    conn.rollback()

                # è·å–æ‰€æœ‰è¡¨
                tables_result = conn.execute(text("""
                    SELECT tablename FROM pg_tables
                    WHERE schemaname = 'public'
                """))
                all_tables = [row[0] for row in tables_result.fetchall()]

                if all_tables:
                    logger.info(f"æ‰¾åˆ° {len(all_tables)} ä¸ªè¡¨")

                    # ä½¿ç”¨ CASCADE åˆ é™¤æ‰€æœ‰è¡¨ï¼ˆåŒ…æ‹¬ä¾èµ–å…³ç³»ã€ç´¢å¼•ã€åºåˆ—ç­‰ï¼‰
                    for table in all_tables:
                        try:
                            conn.execute(text(f'DROP TABLE IF EXISTS "{table}" CASCADE'))
                            logger.debug(f"  å·²åˆ é™¤è¡¨: {table}")
                        except Exception as e:
                            logger.warning(f"  åˆ é™¤è¡¨ {table} å¤±è´¥: {e}")

                    conn.commit()
                    logger.info(f"âœ… å·²åˆ é™¤ {len(all_tables)} ä¸ªè¡¨åŠå…¶ä¾èµ–å¯¹è±¡")
                else:
                    logger.info("æ²¡æœ‰æ‰¾åˆ°éœ€è¦åˆ é™¤çš„è¡¨")

                # æ¸…ç†å‰©ä½™çš„åºåˆ—
                try:
                    sequences_result = conn.execute(text("""
                        SELECT sequence_name FROM information_schema.sequences
                        WHERE sequence_schema = 'public'
                    """))
                    sequences = [row[0] for row in sequences_result.fetchall()]

                    for seq in sequences:
                        try:
                            conn.execute(text(f'DROP SEQUENCE IF EXISTS "{seq}" CASCADE'))
                            logger.debug(f"  å·²åˆ é™¤åºåˆ—: {seq}")
                        except:
                            pass

                    if sequences:
                        conn.commit()
                        logger.info(f"âœ… å·²åˆ é™¤ {len(sequences)} ä¸ªåºåˆ—")
                except Exception as e:
                    logger.debug(f"æ¸…ç†åºåˆ—æ—¶å‡ºé”™ï¼ˆå¯èƒ½ä¸å­˜åœ¨ï¼‰: {e}")
                    conn.rollback()

                # æ¸…ç†å­¤ç«‹çš„ç´¢å¼•ï¼ˆéå¸¸é‡è¦ï¼ï¼‰
                try:
                    # è·å–æ‰€æœ‰ç´¢å¼•ï¼ˆæ’é™¤ä¸»é”®å’Œå”¯ä¸€çº¦æŸè‡ªåŠ¨åˆ›å»ºçš„ç´¢å¼•ï¼‰
                    indexes_result = conn.execute(text("""
                        SELECT indexname, tablename FROM pg_indexes
                        WHERE schemaname = 'public'
                        AND indexname NOT LIKE '%_pkey'
                    """))
                    indexes = indexes_result.fetchall()

                    dropped_count = 0
                    for idx_name, table_name in indexes:
                        try:
                            # å°è¯•åˆ é™¤ç´¢å¼•ï¼ˆå¦‚æœè¡¨å·²ä¸å­˜åœ¨ï¼Œç´¢å¼•åº”è¯¥æ˜¯å­¤ç«‹çš„ï¼‰
                            conn.execute(text(f'DROP INDEX IF EXISTS "{idx_name}" CASCADE'))
                            logger.debug(f"  å·²åˆ é™¤ç´¢å¼•: {idx_name}")
                            dropped_count += 1
                        except Exception as e:
                            logger.debug(f"  åˆ é™¤ç´¢å¼• {idx_name} å¤±è´¥: {e}")

                    if dropped_count > 0:
                        conn.commit()
                        logger.info(f"âœ… å·²åˆ é™¤ {dropped_count} ä¸ªå­¤ç«‹ç´¢å¼•")
                except Exception as e:
                    logger.debug(f"æ¸…ç†ç´¢å¼•æ—¶å‡ºé”™: {e}")
                    conn.rollback()

                return True

            return True

    except Exception as e:
        logger.error(f"âŒ æ¸…ç©ºè¿ç§»è®°å½•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return False


def auto_fix_migrations(engine: Engine, force_reset: bool = False):
    """
    è‡ªåŠ¨ä¿®å¤è¿ç§»çŠ¶æ€

    Args:
        engine: æ•°æ®åº“å¼•æ“
        force_reset: æ˜¯å¦å¼ºåˆ¶é‡ç½®ï¼ˆæ¸…ç©ºè¿ç§»è®°å½•ï¼‰
    """
    # æ£€æŸ¥ç¯å¢ƒ
    env = os.getenv("RAILWAY_ENVIRONMENT", os.getenv("ENVIRONMENT", "development"))

    logger.info("="*60)
    logger.info("ğŸ” å¼€å§‹æ£€æŸ¥è¿ç§»çŠ¶æ€")
    logger.info(f"ğŸ“Œ å½“å‰ç¯å¢ƒ: {env}")
    logger.info("="*60)

    # æ£€æŸ¥çŠ¶æ€
    status = check_migration_consistency(engine)

    logger.info(f"ğŸ“Š æ•°æ®åº“çŠ¶æ€:")
    logger.info(f"  â€¢ è¡¨æ€»æ•°: {status['table_count']}")
    logger.info(f"  â€¢ è¿ç§»è®°å½•æ•°: {status['migration_count']}")
    logger.info(f"  â€¢ å…³é”®è¡¨å®Œæ•´: {'âœ…' if status['has_critical_tables'] else 'âŒ'}")

    if status['missing_tables']:
        logger.warning(f"  â€¢ ç¼ºå°‘è¡¨: {', '.join(status['missing_tables'][:5])}")

    # åˆ¤æ–­æ˜¯å¦éœ€è¦ä¿®å¤
    should_fix = False

    if force_reset:
        logger.warning("âš ï¸  RESET_MIGRATIONS=true, å°†å¼ºåˆ¶æ¸…ç©ºè¿ç§»è®°å½•")
        should_fix = True
    elif status['needs_fix']:
        logger.warning("âš ï¸  æ£€æµ‹åˆ°çŠ¶æ€ä¸ä¸€è‡´ï¼Œå°†è‡ªåŠ¨ä¿®å¤")
        should_fix = True
    else:
        logger.info("âœ… è¿ç§»çŠ¶æ€æ­£å¸¸ï¼Œæ— éœ€ä¿®å¤")

    # æ‰§è¡Œä¿®å¤
    if should_fix:
        # ç”Ÿäº§ç¯å¢ƒéœ€è¦é¢å¤–ç¡®è®¤
        if env.lower() == "production":
            logger.error("âŒ ç”Ÿäº§ç¯å¢ƒä¸å…è®¸è‡ªåŠ¨é‡ç½®è¿ç§»ï¼")
            logger.error("è¯·æ‰‹åŠ¨æ£€æŸ¥å¹¶ä¿®å¤")
            return False

        logger.info("ğŸ”„ å¼€å§‹ä¿®å¤...")

        # æ£€æŸ¥æ˜¯å¦éœ€è¦åˆ é™¤æ‰€æœ‰è¡¨ï¼ˆå®Œå…¨é‡ç½®ï¼‰
        # DROP_ALL_TABLES=true å°†åˆ é™¤æ‰€æœ‰è¡¨å¹¶é‡æ–°åˆ›å»º
        drop_tables = os.getenv("DROP_ALL_TABLES", "false").lower() == "true"

        if drop_tables:
            logger.warning("âš ï¸  DROP_ALL_TABLES=trueï¼Œå°†åˆ é™¤æ‰€æœ‰æ•°æ®åº“è¡¨ï¼")
            logger.warning("âš ï¸  è¿™å°†æ¸…é™¤æ‰€æœ‰æ•°æ®ï¼Œè¯·ç¡®ä¿è¿™æ˜¯æ‚¨æƒ³è¦çš„æ“ä½œï¼")

        success = reset_migration_records(engine, drop_tables=drop_tables)

        if success:
            if drop_tables:
                logger.info("âœ… ä¿®å¤å®Œæˆï¼å·²åˆ é™¤æ‰€æœ‰è¡¨ï¼Œåº”ç”¨å°†é‡æ–°åˆ›å»ºè¡¨å¹¶æ‰§è¡Œæ‰€æœ‰è¿ç§»")
            else:
                logger.info("âœ… ä¿®å¤å®Œæˆï¼åº”ç”¨å°†é‡æ–°åˆ›å»ºç¼ºå¤±çš„è¡¨å¹¶æ‰§è¡Œæ‰€æœ‰è¿ç§»")
            logger.info("="*60)
            return True
        else:
            logger.error("âŒ ä¿®å¤å¤±è´¥")
            return False

    logger.info("="*60)
    return True


def run_auto_fix_if_needed(engine: Engine):
    """
    æ ¹æ®ç¯å¢ƒå˜é‡å†³å®šæ˜¯å¦è¿è¡Œè‡ªåŠ¨ä¿®å¤

    ç¯å¢ƒå˜é‡:
        RESET_MIGRATIONS=true: å¼ºåˆ¶é‡ç½®è¿ç§»è®°å½•
        FIX_MIGRATIONS=true: æ™ºèƒ½æ£€æµ‹å¹¶ä¿®å¤ï¼ˆæ¨èï¼‰
        DROP_ALL_TABLES=true: åˆ é™¤æ‰€æœ‰æ•°æ®åº“è¡¨å¹¶é‡æ–°åˆ›å»ºï¼ˆâš ï¸ å±é™©ï¼šä¼šæ¸…é™¤æ‰€æœ‰æ•°æ®ï¼‰
    """
    # æ£€æŸ¥æ˜¯å¦å¯ç”¨è‡ªåŠ¨ä¿®å¤
    reset_migrations = os.getenv("RESET_MIGRATIONS", "false").lower() == "true"
    fix_migrations = os.getenv("FIX_MIGRATIONS", "false").lower() == "true"

    if reset_migrations or fix_migrations:
        logger.info("ğŸ”§ è‡ªåŠ¨ä¿®å¤å·²å¯ç”¨")
        auto_fix_migrations(engine, force_reset=reset_migrations)
    else:
        # å³ä½¿æ²¡æœ‰å¯ç”¨ï¼Œä¹Ÿåšä¸€ä¸ªå¿«é€Ÿæ£€æŸ¥å¹¶è®°å½•çŠ¶æ€
        status = check_migration_consistency(engine)
        if status['needs_fix']:
            logger.warning("="*60)
            logger.warning("âš ï¸  æ£€æµ‹åˆ°è¿ç§»çŠ¶æ€ä¸ä¸€è‡´ï¼")
            logger.warning(f"  â€¢ è¿ç§»è®°å½•: {status['migration_count']} æ¡")
            logger.warning(f"  â€¢ ç¼ºå°‘å…³é”®è¡¨: {len(status['missing_tables'])} ä¸ª")
            logger.warning("")
            logger.warning("ğŸ’¡ å»ºè®®ä¿®å¤æ–¹æ¡ˆ:")
            logger.warning("  1. åœ¨ Railway ç¯å¢ƒå˜é‡ä¸­æ·»åŠ : FIX_MIGRATIONS=true")
            logger.warning("  2. é‡æ–°éƒ¨ç½²åº”ç”¨")
            logger.warning("  3. ä¿®å¤å®Œæˆååˆ é™¤è¯¥ç¯å¢ƒå˜é‡")
            logger.warning("="*60)
