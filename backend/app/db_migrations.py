"""
æ•°æ®åº“è¿ç§»å·¥å…·
è‡ªåŠ¨è¿è¡Œ migrations ç›®å½•ä¸‹çš„ SQL è„šæœ¬
"""
import os
import logging
from pathlib import Path
from sqlalchemy import text
from sqlalchemy.engine import Engine

logger = logging.getLogger(__name__)

# è¿ç§»è„šæœ¬ç›®å½•
MIGRATIONS_DIR = Path(__file__).parent.parent / "migrations"

# å·²æ‰§è¡Œçš„è¿ç§»è®°å½•è¡¨å
MIGRATION_TABLE = "schema_migrations"


def ensure_migration_table(engine: Engine):
    """ç¡®ä¿è¿ç§»è®°å½•è¡¨å­˜åœ¨"""
    with engine.connect() as conn:
        conn.execute(text(f"""
            CREATE TABLE IF NOT EXISTS {MIGRATION_TABLE} (
                id SERIAL PRIMARY KEY,
                migration_name VARCHAR(255) UNIQUE NOT NULL,
                executed_at TIMESTAMP WITH TIME ZONE DEFAULT CURRENT_TIMESTAMP,
                execution_time_ms INTEGER
            )
        """))
        conn.commit()


def is_migration_executed(engine: Engine, migration_name: str) -> bool:
    """æ£€æŸ¥è¿ç§»æ˜¯å¦å·²æ‰§è¡Œ"""
    try:
        with engine.connect() as conn:
            result = conn.execute(
                text(f"SELECT 1 FROM {MIGRATION_TABLE} WHERE migration_name = :name"),
                {"name": migration_name}
            )
            return result.fetchone() is not None
    except Exception as e:
        logger.warning(f"æ£€æŸ¥è¿ç§»çŠ¶æ€å¤±è´¥: {e}ï¼Œå‡è®¾æœªæ‰§è¡Œ")
        return False


def mark_migration_executed(engine: Engine, migration_name: str, execution_time_ms: int):
    """æ ‡è®°è¿ç§»å·²æ‰§è¡Œ"""
    try:
        with engine.connect() as conn:
            conn.execute(
                text(f"""
                    INSERT INTO {MIGRATION_TABLE} (migration_name, execution_time_ms)
                    VALUES (:name, :time)
                    ON CONFLICT (migration_name) DO NOTHING
                """),
                {"name": migration_name, "time": execution_time_ms}
            )
            conn.commit()
    except Exception as e:
        logger.error(f"æ ‡è®°è¿ç§»æ‰§è¡ŒçŠ¶æ€å¤±è´¥: {e}")


def execute_sql_file(engine: Engine, sql_file: Path) -> tuple[bool, int]:
    """
    æ‰§è¡Œ SQL æ–‡ä»¶
    
    Returns:
        (success: bool, execution_time_ms: int)
    """
    import time
    start_time = time.time()
    
    try:
        # ä½¿ç”¨ autocommit æ¨¡å¼æ‰§è¡Œè¿ç§»ï¼Œé¿å…äº‹åŠ¡é”™è¯¯å½±å“
        with engine.connect() as conn:
            # è®¾ç½® autocommit æ¨¡å¼
            conn = conn.execution_options(autocommit=True)
            
            # è¯»å– SQL æ–‡ä»¶å†…å®¹
            sql_content = sql_file.read_text(encoding='utf-8')
            
            # ä½¿ç”¨ psycopg2 çš„ execute æ–¹æ³•æ‰§è¡Œæ•´ä¸ª SQL æ–‡ä»¶
            # è¿™æ ·å¯ä»¥æ­£ç¡®å¤„ç†å‡½æ•°å®šä¹‰ã€æ³¨é‡Šç­‰å¤æ‚æƒ…å†µ
            try:
                # è·å–åŸå§‹è¿æ¥ï¼ˆpsycopg2 connectionï¼‰
                raw_conn = conn.connection.dbapi_connection
                
                # ä½¿ç”¨ psycopg2 çš„ execute æ–¹æ³•æ‰§è¡Œ SQL
                # ä½¿ç”¨ execute_batch æˆ–é€è¯­å¥æ‰§è¡Œä»¥ç¡®ä¿æ­£ç¡®å¤„ç†
                with raw_conn.cursor() as cursor:
                    # ä½¿ç”¨ psycopg2 çš„ execute æ–¹æ³•ï¼Œå®ƒä¼šè‡ªåŠ¨å¤„ç†å¤šè¯­å¥
                    # åœ¨ autocommit æ¨¡å¼ä¸‹ï¼Œæ¯ä¸ªè¯­å¥è‡ªåŠ¨æäº¤
                    cursor.execute(sql_content)
                    raw_conn.commit()
            except (AttributeError, Exception) as e:
                # å¦‚æœ psycopg2 æ–¹å¼å¤±è´¥ï¼Œè®°å½•é”™è¯¯å¹¶ä½¿ç”¨ SQLAlchemy æ–¹å¼
                logger.debug(f"psycopg2 æ‰§è¡Œå¤±è´¥ï¼Œä½¿ç”¨ SQLAlchemy æ–¹å¼: {e}")
                # å¦‚æœä¸æ˜¯ psycopg2 è¿æ¥ï¼Œå›é€€åˆ° SQLAlchemy æ–¹å¼
                # ç®€å•å¤„ç†ï¼šæŒ‰åˆ†å·åˆ†å‰²ï¼Œä½†è·³è¿‡æ³¨é‡Šè¡Œ
                statements = []
                current_statement = []
                in_do_block = False
                
                for line in sql_content.split('\n'):
                    stripped = line.strip()
                    
                    # è·³è¿‡ç©ºè¡Œå’Œæ³¨é‡Šè¡Œ
                    if not stripped or stripped.startswith('--'):
                        continue
                    
                    # æ£€æµ‹ DO $$ å—
                    if 'DO $$' in stripped.upper():
                        in_do_block = True
                    
                    current_statement.append(line)
                    
                    # å¦‚æœè¡Œä»¥åˆ†å·ç»“å°¾ï¼Œç»“æŸå½“å‰è¯­å¥
                    if stripped.endswith(';'):
                        if in_do_block and 'END $$;' in stripped.upper():
                            in_do_block = False
                        statement = '\n'.join(current_statement).strip()
                        if statement:
                            statements.append(statement)
                        current_statement = []
                
                # å¤„ç†æœ€åä¸€ä¸ªè¯­å¥ï¼ˆå¯èƒ½æ²¡æœ‰åˆ†å·ï¼‰
                if current_statement:
                    statement = '\n'.join(current_statement).strip()
                    if statement:
                        statements.append(statement)
                
                # æ‰§è¡Œæ¯ä¸ªè¯­å¥ï¼ˆæ¯ä¸ªè¯­å¥ç‹¬ç«‹äº‹åŠ¡ï¼‰
                for i, statement in enumerate(statements, 1):
                    if statement:
                        # æ¯ä¸ªè¯­å¥åœ¨ç‹¬ç«‹äº‹åŠ¡ä¸­æ‰§è¡Œ
                        trans = conn.begin()
                        try:
                            conn.execute(text(statement))
                            trans.commit()
                        except Exception as e:
                            trans.rollback()
                            # æŸäº›è¯­å¥å¯èƒ½å› ä¸ºå·²å­˜åœ¨è€Œå¤±è´¥ï¼ˆå¦‚ CREATE INDEX IF NOT EXISTSï¼‰
                            # è®°å½•è­¦å‘Šä½†ç»§ç»­æ‰§è¡Œ
                            error_msg = str(e).lower()
                            if any(keyword in error_msg for keyword in [
                                "already exists", "duplicate", "does not exist",
                                "already has", "relation already exists",
                                "constraint.*already exists", "already exists"
                            ]):
                                logger.debug(f"è¯­å¥å·²å­˜åœ¨æˆ–å·²åˆ é™¤ï¼Œè·³è¿‡ ({i}/{len(statements)}): {statement[:50]}...")
                            elif "current transaction is aborted" in error_msg:
                                # äº‹åŠ¡ä¸­æ­¢é”™è¯¯ï¼Œå·²å›æ»šï¼Œç»§ç»­æ‰§è¡Œä¸‹ä¸€ä¸ª
                                logger.warning(f"äº‹åŠ¡ä¸­æ­¢ï¼Œå·²å›æ»šï¼Œç»§ç»­ ({i}/{len(statements)}): {statement[:50]}...")
                                continue
                            else:
                                # è®°å½•é”™è¯¯ä½†ç»§ç»­æ‰§è¡Œ
                                logger.warning(f"æ‰§è¡Œè¯­å¥æ—¶å‡ºé”™ï¼ˆç»§ç»­æ‰§è¡Œï¼‰ ({i}/{len(statements)}): {e}")
                                logger.debug(f"é—®é¢˜è¯­å¥: {statement[:100]}...")
                                # ç»§ç»­æ‰§è¡Œä¸‹ä¸€ä¸ªè¯­å¥
                                continue
            
        execution_time = int((time.time() - start_time) * 1000)
        return True, execution_time
        
    except Exception as e:
        logger.error(f"æ‰§è¡Œ SQL æ–‡ä»¶å¤±è´¥ {sql_file.name}: {e}")
        return False, int((time.time() - start_time) * 1000)


def run_migrations(engine: Engine, force: bool = False):
    """
    è¿è¡Œæ‰€æœ‰æœªæ‰§è¡Œçš„è¿ç§»è„šæœ¬
    
    Args:
        engine: SQLAlchemy å¼•æ“
        force: æ˜¯å¦å¼ºåˆ¶é‡æ–°æ‰§è¡Œæ‰€æœ‰è¿ç§»ï¼ˆç”¨äºå¼€å‘ç¯å¢ƒï¼‰
    """
    if not MIGRATIONS_DIR.exists():
        logger.warning(f"è¿ç§»ç›®å½•ä¸å­˜åœ¨: {MIGRATIONS_DIR}")
        return
    
    # ç¡®ä¿è¿ç§»è®°å½•è¡¨å­˜åœ¨
    ensure_migration_table(engine)
    
    # è·å–æ‰€æœ‰ SQL æ–‡ä»¶ï¼ŒæŒ‰æ–‡ä»¶åæ’åº
    sql_files = sorted(MIGRATIONS_DIR.glob("*.sql"))
    
    if not sql_files:
        logger.info("æ²¡æœ‰æ‰¾åˆ°è¿ç§»è„šæœ¬")
        return
    
    logger.info(f"æ‰¾åˆ° {len(sql_files)} ä¸ªè¿ç§»è„šæœ¬")
    
    executed_count = 0
    skipped_count = 0
    failed_count = 0
    
    for sql_file in sql_files:
        migration_name = sql_file.name
        
        # æ£€æŸ¥æ˜¯å¦å·²æ‰§è¡Œ
        if not force and is_migration_executed(engine, migration_name):
            logger.info(f"â­ï¸  è·³è¿‡å·²æ‰§è¡Œçš„è¿ç§»: {migration_name}")
            skipped_count += 1
            continue
        
        logger.info(f"ğŸ”„ æ‰§è¡Œè¿ç§»: {migration_name}")
        
        success, execution_time = execute_sql_file(engine, sql_file)
        
        if success:
            mark_migration_executed(engine, migration_name, execution_time)
            logger.info(f"âœ… è¿ç§»æ‰§è¡ŒæˆåŠŸ: {migration_name} (è€—æ—¶: {execution_time}ms)")
            executed_count += 1
        else:
            logger.error(f"âŒ è¿ç§»æ‰§è¡Œå¤±è´¥: {migration_name}")
            failed_count += 1
    
    logger.info(f"è¿ç§»å®Œæˆ: {executed_count} ä¸ªå·²æ‰§è¡Œ, {skipped_count} ä¸ªå·²è·³è¿‡, {failed_count} ä¸ªå¤±è´¥")


def run_specific_migration(engine: Engine, migration_name: str, force: bool = False):
    """
    è¿è¡ŒæŒ‡å®šçš„è¿ç§»è„šæœ¬
    
    Args:
        engine: SQLAlchemy å¼•æ“
        migration_name: è¿ç§»æ–‡ä»¶åï¼ˆå¦‚ "fix_conversation_key.sql"ï¼‰
        force: æ˜¯å¦å¼ºåˆ¶é‡æ–°æ‰§è¡Œ
    """
    sql_file = MIGRATIONS_DIR / migration_name
    
    if not sql_file.exists():
        logger.error(f"è¿ç§»æ–‡ä»¶ä¸å­˜åœ¨: {migration_name}")
        return False
    
    if not force and is_migration_executed(engine, migration_name):
        logger.info(f"è¿ç§»å·²æ‰§è¡Œ: {migration_name}")
        return True
    
    logger.info(f"æ‰§è¡Œè¿ç§»: {migration_name}")
    success, execution_time = execute_sql_file(engine, sql_file)
    
    if success:
        mark_migration_executed(engine, migration_name, execution_time)
        logger.info(f"è¿ç§»æ‰§è¡ŒæˆåŠŸ: {migration_name} (è€—æ—¶: {execution_time}ms)")
        return True
    else:
        logger.error(f"è¿ç§»æ‰§è¡Œå¤±è´¥: {migration_name}")
        return False
